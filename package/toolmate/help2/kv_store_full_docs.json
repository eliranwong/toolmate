{
  "doc-60d58b7ce45cfee61330ecc133c0504d": {
    "content": "# Speech Settings\n\nEnter `.speechrecognition` to configure speech recognition settings.\n\nEnter `.speechgeneration` to configure speech generation settings."
  },
  "doc-fb3f71c5dc50e2ed48684a953a02ae59": {
    "content": "# Offline TTS - Windows\n\nToolMate v0.2.42+ integrates [wsay](https://github.com/p-groarke/wsay) on Windows for text-to-speech feature.\n\n# Download 'wsay.exe'\n\nFrom version 0.2.61 of ToolMate AI, 'wsay.exe' is automatically downloaded, to '~\\\\toolmate' by default, when 'Wsay' is selected as the voice generation interface.\n\nCurrent code install [v1.6.2 version of wsay](https://github.com/p-groarke/wsay/releases/tag/1.6.2).  You may manually install other versions. Read: https://github.com/p-groarke/wsay#install-instructions\n\n# Setup\n\n1. Select \"change voice generation config\" from action menu\n\n2. Select \"Wsay\" from available options\n\n3. Select a voice\n\n4. Specify Speed\n\n5. Select \"toggle input audio\" from action menu, to enable / disable reading input text\n\n6. Select \"toggle output audio\" from action menu, to enable / disable reading output text"
  },
  "doc-a20c03fd3da0be0136aad190e9cd56e6": {
    "content": "# Reflection Agents\n\nTwo reflection agents are developed to mimic the reflection feature performed by the LLM [Reflection Llama 3.1 70b](https://huggingface.co/mattshumer/Reflection-Llama-3.1-70B).  Both are created to work with any LLMs, without the need of running Reflection Llama 3.1 70b.\n\n`@reflection` - to reflect on a given query\n\n`@deep_reflection` - to reflect deeply and in detail on a given query\n\nTo compare these two tools, both follow a `Think -> Review -> Refine` pattern, but `@deep_reflection` provides a more detailed analysis and response than `@reflection`.\n\n# How to Use\n\nFirst, make sure plugin `reflection` is enabled.\n\nEnter either `@reflection ` or `@deep_reflection ` followed by your query\n\nFor examples:\n\n```\n@reflection Is it better to drink wine in the morning, afternoon, or evening?     \n```\n\n```\n@deep_reflection Is it better to drink wine in the morning, afternoon, or evening?     \n```\n\n# An Example \n\nIn this example, we ask the same model, \"mixtral-8x7b-32768,\" the same query, \"Is it better to drink wine in the morning, afternoon, or evening?\", comparing tools \"@reflection\" and \"@deep_reflection.\"\n\n## Reflection\n\nInput:\n\n```\n@reflection Is it better to drink wine in the morning, afternoon, or evening?     \n```\n\nOutput:\n\n```  \n@chat: `Reflection` Is it better to drink wine in the morning, afternoon, or evening? \n\n<thinking>\nI will approach this query by considering the potential effects of drinking wine at different times of the day. This \nwill involve examining factors such as the body's internal clock, or circadian rhythm, and how alcohol metabolism varies\nthroughout the day. \n\n1. Investigate the body's circadian rhythm and its potential impact on alcohol metabolism.\n2. Examine how alcohol metabolism varies at different times of the day.\n3. Analyze the social implications of drinking wine in the morning, afternoon, and evening.\n\n<reflection>\nIn my initial thinking, I've outlined a plan to investigate the body's internal clock and alcohol metabolism, as well as\nsocial implications. This approach should provide a comprehensive answer, considering both physiological and societal \nfactors. \n\n1. The body's circadian rhythm and alcohol metabolism are well-researched topics, so I am confident in my ability to \nfind relevant information.\n2. Social implications may vary depending on cultural norms, so I should ensure to consider a variety of perspectives.\n</reflection>\n\n</thinking>\n\n<output>\nAfter considering the body's circadian rhythm and alcohol metabolism, as well as social implications, I can conclude \nthat it is generally better to drink wine in the evening. \n\n1. The body's circadian rhythm: The body's internal clock regulates various physiological processes, including metabol\nism. A study published in the journal \"Alcoholism: Clinical and Experimental Research\" found that alcohol is metabolized\nmore slowly in the morning, which could lead to higher blood alcohol concentrations and potentially more severe hango\nvers.\n\n2. Alcohol metabolism: Alcohol is metabolized by the liver, which has a limited capacity to process alcohol. Drinking \nwine in the evening allows the liver more time to metabolize the alcohol before the next day's activities.\n\n3. Social implications: Drinking wine in the morning or afternoon may be seen as inappropriate or indicative of a \nproblem in many cultures. Drinking in the evening, particularly with meals, is a more socially accepted time for alcohol\nconsumption.\n\nIn conclusion, drinking wine in the evening is the most appropriate time, considering both the body's circadian rhythm \nand alcohol metabolism, as well as social norms and expectations.\n</output>\n```\n\n## Deep Reflection\n\nInput:\n\n```\n@deep_reflection Is it better to drink wine in the morning, afternoon, or evening?     \n```\n\nOutput:\n\n```                                 \n@chat: `Think` Is it better to drink wine in the morning, afternoon, or evening? \n\n<thinking>\n\n1. Understand the Query:\n   a. The main question is about the best time of the day to drink wine.\n   b. There are no explicit constraints or limitations mentioned.\n   c. The expected output format is a well-reasoned answer.\n\n2. Outline the Approach:\n   a. This query requires factual recall and logical reasoning.\n   b. I will first recall general knowledge about wine and its effects on the body.\n   c. Then, I will consider the typical daily routines and activities to determine the most suitable time.\n\n3. Present a Plan:\n   a. Recall general knowledge about wine and its effects on the body.\n   b. Identify typical daily routines and activities.\n   c. Consider the effects of wine consumption during different times of the day.\n   d. Provide a well-reasoned answer.\n\n</thinking>\n\nWhile it's a matter of personal preference, there are some factors to consider when determining the best time of the day\nto drink wine. Wine, especially red wine, contains alcohol and antioxidants, which can have various effects on the body.\n\nTypical daily routines and activities can also influence the best time for wine consumption. Here's a breakdown of the \nday with these factors in mind:\n\nMorning:\n- Alcohol can cause dehydration, which might lead to headaches or fatigue, affecting productivity.\n- Drinking wine in the morning is generally not recommended due to its potential impact on focus and daily activities.\n\nAfternoon:\n- After a meal, wine can aid digestion and help you relax.\n- However, consuming alcohol in the afternoon might interfere with work or other responsibilities, depending on \nindividual tolerance and the amount consumed.\n\nEvening:\n- Wine can be a great way to unwind after a long day.\n- Consuming wine in moderation during the evening is generally more socially acceptable and less likely to interfere \nwith daily activities.\n\nIn conclusion, drinking wine in the evening is often the most suitable time, considering its effects on the body and \ntypical daily routines. However, personal preferences and individual tolerance to alcohol should always be taken into \naccount. Remember, moderation is key.\n\n\n@chat: Review, evaluate, and reflect ...\n\n1. Context and Original Query:\n\n   a. Identify the Original Query: <content>Is it better to drink wine in the morning, afternoon, or evening?</content>\n   \n   b. Describe the Intended Audience and Purpose: The response is intended for a general audience interested in learning\nabout the best time of day to drink wine based on its effects on the body and typical daily routines.\n\n2. Thorough Review of the Response:\n\n   a. Accuracy and Factual Correctness: The information provided in the response is generally accurate and up-to-date.\n   \n   b. Relevance and Completeness: The response fully addresses the original prompt by considering the effects of wine \nconsumption during different times of the day and providing a well-reasoned answer.\n   \n   c. Coherence and Organization: The response is well-organized and easy to follow, progressing logically from the \nintroduction of the topic to the conclusion.\n   \n   d. Clarity and Conciseness: The response is clear and concise, using appropriate language for the general audience.\n   \n   e. Tone and Style: The tone and style of the response are informative and engaging, suitable for the intended \naudience and purpose.\n\n3. Potential Errors and Oversights:\n\n   a. Identify Factual Errors: No specific factual errors were found in the response.\n   \n   b. Highlight Gaps in Information: The response could benefit from additional information on the specific effects of \nwine consumption during different times of the day, such as the impact on sleep patterns or metabolism.\n   \n   c. Address Logical Fallacies: No logical fallacies were identified in the response.\n   \n   d. Check for Biases or Assumptions: The response does not exhibit any unintended biases or rely on unstated \nassumptions.\n\n4. Suggestions for Improvement:\n\n   a. Correct Factual Errors: Not applicable in this case.\n   \n   b. Fill Information Gaps: Consider including more specific information on the effects of wine consumption during \ndifferent times of the day, such as the impact on sleep patterns or metabolism.\n   \n   c. Strengthen Logical Reasoning: Not necessary for this response.\n   \n   d. Address Biases and Assumptions: Not applicable in this case.\n   \n   e. Enhance Clarity and Conciseness: Not necessary for this response.\n   \n   f. Adjust Tone and Style: Not necessary for this response.\n\n5. Overall Assessment and Reflection:\n\n   a. Summarize Strengths and Weaknesses: The response is accurate, relevant, and well-organized, addressing the \noriginal prompt clearly. However, it could benefit from additional specific information on the effects of wine \nconsumption during different times of the day.\n   \n   b. Reflect on Potential Causes of Errors: No errors were identified in the response.\n   \n   c. Suggest Strategies for Future Improvement: To enhance the LLM's performance on similar tasks, consider providing \nmore specific information on the effects of various activities or substances during different times of the day. This \nwill enable the LLM to provide more detailed and informative responses.\n\n\n@chat: Refine ...\n\n<content>Is it better to drink wine in the morning, afternoon, or evening?</content>\n\n<thinking>\n\nTo provide an improved response, let's consider the following factors:\n\n1. General knowledge about wine and its effects on the body.\n2. The typical daily routines and activities.\n3. Specific effects of wine consumption during different times of the day.\n\n</thinking>\n\nWine, particularly red wine, contains alcohol and antioxidants, which can have various effects on the body. Drinking \nwine in moderation can have health benefits, but excessive consumption may lead to negative consequences.\n\nTypical daily routines and activities can influence the best time for wine consumption. Here's a breakdown of the day \nwith these factors in mind:\n\nMorning:\n- Alcohol can cause dehydration, which might lead to headaches or fatigue, affecting productivity.\n- Drinking wine in the morning is generally not recommended due to its potential impact on focus and daily activities.\n\nAfternoon:\n- After a meal, wine can aid digestion and help you relax.\n- Wine contains antioxidants, which may have heart-health benefits when consumed in moderation.\n- However, consuming alcohol in the afternoon might interfere with work or other responsibilities, depending on \nindividual tolerance and the amount consumed.\n\nEvening:\n- Wine can be a great way to unwind after a long day.\n- Consuming wine in moderation during the evening is generally more socially acceptable and less likely to interfere \nwith daily activities.\n- Drinking wine in the evening may also help improve sleep quality for some individuals, as it can promote relaxation.\n\nIn conclusion, drinking wine in the evening is often the most suitable time, considering its effects on the body and \ntypical daily routines. However, personal preferences and individual tolerance to alcohol should always be taken into \naccount. Remember, moderation is key.\n\nFor additional context, it's worth noting that some studies suggest that the best time to drink wine may be during meals\n, as it can aid digestion and help absorb nutrients. Additionally, consuming wine during meals may reduce the risk of \nnegative effects associated with excessive alcohol consumption.\n```"
  },
  "doc-8bf45d78cbe1a36e98504649363c4920": {
    "content": "# Offline TTS - Linux\n\nToolMate v0.2.7+ integrates [piper-tts](https://github.com/rhasspy/piper) on Linux for offline text-to-speech feature.\n\nPlease note that piper-tts does not support Windows or macOS at the time of writing.\n\n# Setup\n\n1. Install piper-tss, e.g.\n\n> cd ~/dev # this path depends on where your environment directory locates\n\n> source toolmate/bin/activate\n\n> pip install piper-tts\n\n2. Select \"change text-to-speech config\" from action menu:\n\n![piper1](https://github.com/eliranwong/toolmate/assets/25262722/6ec8a98b-4a12-49b3-99b5-d45683ee66f9)\n\n3. Select \"Piper\" from available tts options:\n\n![piper2](https://github.com/eliranwong/toolmate/assets/25262722/ffe1a21d-9f7e-431e-bcbb-07f09f3e0535)\n\n4. Select a piper voice model:\n\n(Details: https://github.com/rhasspy/piper/blob/master/VOICES.md)\n\n![piper3](https://github.com/eliranwong/toolmate/assets/25262722/e2c841a6-3622-419e-bcdf-0301fccb74fb)\n\n5. You can optionally specify voice speed if you have \"[VLC player](https://www.videolan.org)\" or \"cvlc\" command installed.\n\n6. Select \"toggle input audio\" from action menu, to enable / disable reading input text\n\n7. Select \"toggle output audio\" from action menu, to enable / disable reading output text\n\n# Download More Voices\n\nVoices are automatically downloaded when you first use them.\n\nThey are stored at ~/toolmate/LLMs/piper/ by default.\n\nYou can also manually downloaded more voices from https://github.com/rhasspy/piper/blob/master/VOICES.md and place them in the folder.\n\n![piper_voice_storage](https://github.com/eliranwong/toolmate/assets/25262722/9c9f8d43-884f-4ff1-bb17-4fbdbd895c56)"
  },
  "doc-553045fd78498fa25ba7b348b3528cdf": {
    "content": "# Action Menu\n\nYou can configure some settings or launch some actions via ToolMate action menu.\n\n![action_menu_0](https://github.com/eliranwong/letmedoit/assets/25262722/5519d920-94db-4575-b66f-0f4a7549544e)\n\n# Launch Action Menu\n\nEnter a blank entry '' in the ToolMate AI prompt to launch the action menu.\n\n# Shortcut Keys\n\nSome actions are assigned with shortcut keys, e.g. 'ctrl+n' to start a new start directly without launching the action menu.\n\nFor a full list of key bindings, press 'ctrl+k' or enter '.keys' in ToolMate prompt.\n\n# Shortcut Entries\n\nShortcut entries that starts with a dot '.' trigger a quick action directly.\n\nFor example, entering '.new' to start a new chat, '.exit' to exit the current feature or the app, etc.\n\nPress 'ctrl+k' and scroll to the bottom for a full list of quick actions, e.g.:\n\n```\n.new: start a new conversation ['c-n']\n.open: open a saved conversation ['c-o']\n.save: save current conversation\n.saveas: save current conversation as ...\n.export: export current conversation ['c-g']\n.model: change AI backends and models\n.apikeys: change API keys\n.plugins: change plugins\n.tools: change tool configurations\n.managerisk: manage code execution risk\n.context: change default context\n.contextwindow: change context window size\n.temperature: change output temperature\n.maxtokens: change maximum output tokens\n.maxmemorymatches: change maximum memory matches\n.maxchatrecordmatches: change maximum chat record matches\n.maxonlinesearches: change maximum online search results\n.ipinfo: change ip information integration\n.latestSearches: change online searches\n.codedisplay: change code display\n.pagerview: change pager view\n.speechrecognition: change sppech recognition\n.speechgeneration: change sppech generation\n.read: read the last response\n.toggledeveloper: toggle developer mode ['escape', 'd']\n.togglemultiline: toggle multi-line input ['escape', 'l']\n.togglemousesupport: toogle mouse support ['escape', 'm']\n.toggletextbrightness: swap text brightness ['escape', 'b']\n.togglewordwrap: toggle word wrap ['c-w']\n.toggleinputimprovement: toggle input improvement ['escape', 'w']\n.toggleinputaudio: toggle input audio ['escape', 'y']\n.toggleoutputaudio: toggle output audio ['c-y']\n.customtexteditor: change custom text editor\n.editresponse: edit the last response ['escape', 'e']\n.editconfigs: edit configuration settings\n.autoupgrade: change automatic upgrade\n.assistantname: change assistant name\n.storagedirectory: change storage directory\n.systemmessage: change system messages\n.system: open system command prompt ['escape', 't']\n.install: install python package\n.keys: display key bindings ['c-k']\n.help: open documentations\n.donate: donate and support ToolMate AI\n```\n\n# Input suggestions\n\nYou don't need to memorise all actions, you may simply type a keyword and get some suggestions, e.g. type \"model\"\n\n![action_menu_1](https://github.com/eliranwong/letmedoit/assets/25262722/0030aa56-8806-4ec7-b578-007202bc24ce)\n\n# Filter the Action Menu\n\nYou can filter the action menu with a keyword.\n\ne.g. to filter options related to 'model', enter\n\n> .model\n\n![action_menu_2](https://github.com/eliranwong/letmedoit/assets/25262722/4e552377-7568-49e6-88ad-c7c6dc3a984e)"
  },
  "doc-56777ce328a2ecdf2846a29756d6b7e4": {
    "content": "# Install ffmpeg\n\nYou need to install 'ffmpeg' in order to work with plugin 'download youtube media'.\n\n# Examples\n\nThere are different ways to install 'ffmpeg'.  Read for details at: https://www.ffmpeg.org/\n\nWe briefly describe some examples below.\n\n    [on Linux]<br>\n    - Run in terminal:\n    > sudo apt install ffmpeg\n\n    [on Windows]\n    - Install \"chocolatey\" first. read https://chocolatey.org/install\n    - open Windows PowerShell (Admin), and run:\n    > choco install ffmpeg\n\n    Add ffmpeg path:<br>\n    1) Search in Windows search bar \"Edit the system environment variables\", and open it\n    2) Select \"System Variables\" > \"Path\" > \"Edit\" > \"New\"\n    3) Enter \"C:\\ProgramData\\chocolatey\\lib\\ffmpeg\\tools\\ffmpeg\\bin\\\"\n    4) Click \"OK\"\n\n    [on macOS]\n    - Install \"homebrew\" first. read https://brew.sh/\n    - Run in terminal:\n    > brew install ffmpeg"
  },
  "doc-25458b999205320a96ad26b8f7b70cab": {
    "content": "# Android Version\n\nYou can run ToolMate AI on Android via Termux.\n\n![android](https://github.com/user-attachments/assets/21775454-bd8e-412b-86ab-54e424ed1754)\n\n# Do NOT use Play Store to Install Termux\n\nThe following instructions install the offical `termux` package downloaded from github repository.\n\n# FIRST, Give Permission to Chrome App\n\nWe will describe how to install the Termux apk file via Chrome app, but first you need to enable your Chrome app to install unknown app.\n\n1. Go to `Settings` > `Apps` > `Special app access` > `Install unknown apps`\n\n2. Select Chrome\n\n3. Enable \"Allow from this source\"\n\n<b>Remarks:</b> You may disable this feature after you install Termux app.\n\n# Install Termux App\n\n1. Launch Chrome on your Android device.\n\n2. Go to official Termux GitHub release page: https://github.com/termux/termux-app/releases\n\n3. Download the \"universal\" version from the list under \"Assets\"\n\n4. After the file is downloaded, select it from Chrome download list\n\n5. Select \"Install\"\n\n# Install Repositories\n\nLaunch Termux and run,\n\n> pkg install root-repo\n\n> pkg install x11-repo\n\n# Update and Upgrade\n\n> pkg upgrade\n\n# Termux:API & termux-api\n\nTermux:API app and termux-api package are two different elements that needed to be installed separately.\n\n1. Download and install a `*.apk` file from https://github.com/termux/termux-api/releases\n\n2. Run in termux:\n\n> pkg install termux-api\n\nRead more at https://wiki.termux.com/wiki/Termux:API\n\n# Storage Setup\n\nGo to `Settings` > `Apps` > `Termux` > `Permissions` > `Files` > `Allow`\n\n> termux-setup-storage\n\nLocate the shared storage in `$HOME/storage`\n\nRead more at https://wiki.termux.com/wiki/Sharing_Data\n\n# Install Basic Packages\n\n> pkg install python git binutils libjpeg-turbo libpng build-essential clang make pkg-config curl wget lynx w3m elinks vlc xclip xsel vim libxml2 libxslt python-apsw which libzmq libsodium libgmp libmpc libmpfr python-lxml which micro nano rust proot python-torch python-torchaudio python-torchvision\n\nRemarks:\n\n1. We install the official python-apsw package created by Termux team, rather than using pip3, in order to work with regular expression searches.  For details, read https://github.com/termux/termux-packages/issues/12340\n\n2. Installation of `rust` is necessary for several python packages to be installed.\n\nRead more at: https://wiki.termux.com/wiki/Python#Python_module_installation_tips_and_tricks\n\n# More about Packages\n\nhttps://wiki.termux.com/wiki/Package_Management#Other_Package_Managers\n\nhttps://wiki.termux.com/wiki/Python\n\n# Install matplotlib on Termux\n\nOn Termux, do not use pip3 to install matplotlib, we manage to install matplotlib on Termux by running:\n\n```\npip3 install 'kiwisolver<1.4.0,>=1.0.1' --force-reinstall\npip3 install cycler\npip3 install fonttools\npip3 install python-dateutil\npkg install python-numpy\npkg install matplotlib\n```\n\n# Instal Ollama on Termux\n\nInstall Ollama:\n\n```\npkg install git cmake golang\ngit clone --depth 1 https://github.com/ollama/ollama.git\ncd ollama\ngo generate ./...\ngo build .\ncp ollama /data/data/com.termux/files/usr/bin/\n```\n\nStart Ollama server:\n\n```\nollama serve &\n```\n\nRun, e.g. Llama3.2:3b:\n\n```\nollama run llama3.2:3b\n```\n\n# Install fabric\n\n```\npkg install golang\ngo install github.com/danielmiessler/fabric@latest\nexport GOPATH=$HOME/go\nexport PATH=$GOPATH/bin:$HOME/.local/bin:$PATH\nfabric --setup\n```\n\n# Install Docker, SearxNG and Perplexica\n\nhttps://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Docker%20Setup%20on%20Android%20Termux.md\n\n# Install yt-dlp\n\n```\ncd\nmkdir -p ~/.local/bin\npkg install ffmpeg\nwget -P ~/.local/bin/ https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp\nchmod +x ~/.local/bin/yt-dlp\nexport PATH=$HOME/.local/bin:$PATH\nalias mp3='cd /data/data/com.termux/files/home/storage/music && yt-dlp -x --audio-format mp3'\nalias mp4='cd /data/data/com.termux/files/home/storage/movies && yt-dlp -f bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\n```\n\n# Install ToolMate_Android\n\n`toolmate_lite` is a light version of `toolmate`, created to work with Termux:API.\n\nSet up a shared folder where you can access content by ToolMate AI, from Termux and Android file manager\n\n```\ncd\nmkdir -p storage/shared/Documents/toolmate\nln -s storage/shared/Documents/toolmate toolmate\n```\n\nInstall ToolMate AI (Android version), by running:\n\nTo set up virtual environment (recommended):\n\n> mkdir -p ~/apps\n\nRemarks: In the first run, `Toolmate AI` automatically creates a directory `~/toolmate`, where user content is stored.  Therefore, it is not recommended to install `Toolmate AI` in `~/toolmate`.\n\n> cd ~/apps\n\n> python -m venv --system-site-packages toolmate\n\n> source toolmate/bin/activate\n\nTo install:\n\n> pip install --upgrade toolmate_lite\n\nIf you want optional integration with [UniqueBible App](https://github.com/eliranwong/UniqueBible):\n\n> pip install --upgrade toolmate_lite[bible]\n\nTo run:\n\n> toolmate\n\nTo start up with a particular backend, you may use parameter `-b`, e.g.:\n\n> toolmate -b groq\n\nTo set up an alias:\n\n> echo \"alias toolmate=~/apps/toolmate/bin/toolmate\" >> ~/.bashrc\n\n# Install ToolMate AI - Full Version\n\nRun in Termux:\n\n```\ncd\nmkdir -p storage/shared/Documents/toolmate\npkg update && pkg upgrade && pkg install -y git wget proot\ngit clone https://github.com/MFDGaming/ubuntu-in-termux.git\ncd ubuntu-in-termux && chmod +x ubuntu.sh && ./ubuntu.sh -y\necho 'alias ubuntu='$(pwd)'/startubuntu.sh' >> ~/.bashrc\necho 'pulseaudio --start --load=\"module-native-protocol-tcp auth-ip-acl=127.0.0.1 auth-anonymous=1\" --exit-idle-time=-1' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n## Start Ubuntu in Termux\n\n```\nubuntu\n```\n\n## Install ToolMate AI\n\nInside the `ubuntu`, run:\n\nBasic:\n\n```\ncd\napt update && apt full-upgrade\napt install -y python3\napt install -y python3-setuptools python3-pip python3-dev python3-venv portaudio19-dev ffmpeg wget curl git wget nano micro sqlite3 libsqlite3-dev net-tools\napt install libxcb-cursor0 pulseaudio-utils alsa-base alsa-utils mpg123 espeak\n# add missing group names\ngroupadd -g 3003 groupname3003\ngroupadd -g 9997 groupname9997\ngroupadd -g 20298 groupname20298\ngroupadd -g 50298 groupname50298\n# support container sound output\necho 'export PULSE_SERVER=127.0.0.1' >> ~/.bashrc\n# install golang\nadd-apt-repository ppa:longsleep/golang-backports\napt update\napt install golang-go\n# install rust\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nexport PATH=$HOME/.cargo/bin:$PATH\n# install fabric\nmkdir -p .local/bin\necho \"export PATH=$HOME/.local/bin:$PATH\" >> ~/.bashrc\ncurl -L https://github.com/danielmiessler/fabric/releases/latest/download/fabric-linux-arm64 > ~/.local/bin/fabric && chmod +x ~/.local/bin/fabric && ~/.local/bin/fabric --setup\n# reload variables\nsource ~/.bashrc\n```\n\nRemarks:\n* Configure the `fabric` before installing running `ToolMate AI`.\n* `libsqlite3-dev` is required for python installing package `pysqlite3`.\n* Rust toolchain is required for installing package `lightrag-hku`\n\n```\ncd\nln -s /data/data/com.termux/files/home/storage/shared/Documents/toolmate toolmate\nmkdir -p ~/apps\ncd ~/apps\npython3 -m venv toolmate\nsource toolmate/bin/activate\npip install --upgrade toolmate[linux]\necho 'alias toolmate='$(pwd)'/toolmate/bin/toolmate' >> ~/.bashrc\necho 'alias sudo=\"\"' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n## Run ToolMate AI\n\n```\ntoolmate\n```\n\nTo exit, enter `.exit` or press `ctrl+q`.\n\n## Exit Ubuntu in Termux\n\n```\nexit\n```"
  },
  "doc-60036d0b640ad5bcf69605ca865480fc": {
    "content": "# Fabric Integration\n\nIntegration of `fabric` has been available from version: 0.2.90+.\n\nEnter `@fabric` or `@append_fabric`, followed by fabric parameters\n\n`@fabric` Execute the given fabric command\n\n`@append_fabric` Append assistant previous response to the given fabric command and execute.\n\n# Requirement\n\nInstall `fabric` separately, read https://github.com/danielmiessler/fabric\n\nSet up `fabric` by running `fabric --setup` in terminal.  This step crucial to enable ToolMate AI to retrieve available `fabric` patterns. If you have `fabric` installed without setting it up, you may experience an issue when you start up ToolMate AI.\n\n# How to use `fabric` with other ToolMate AI tools?\n\nAssuming `fabric` is installed and the ToolMate AI tool plugin `fabric` is enabled, you may run something like:\n\n```\n@fabric -m gemini-1.5-pro -p write_essay \"What is machine learning?\"\n@append_fabric -m llama3.1:latest -p extract_wisdom\n@append_fabric -m mistral-large:123b -p summarize\n@ask_gemini Explain it to a five-year kid\n@ask_chatgpt Translate it into Chinese\n```\n\nFor using multiple tools in a single prompt, read https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Running%20Multiple%20Tools%20in%20One%20Go.md\n\n# Select from Available Fabric Patterns\n\nEnter `@fabric_pattern`, `@append_fabric_pattern`, `@fabric -p` or `@append_fabric -p` followed by a space in ToolMate AI prompt, to get a dropdown list of downloaded fabric patterns.\n\n![fabric_pattern](https://github.com/user-attachments/assets/604f4d51-7573-4209-bd9b-3df408581997)\n\n# Difference from Running Fabric Alone\n\nFabric integration in ToolMate AI brings `fabric` to interact with other AI tools, supported by ToolMate AI. Fabric output is directly integrated into the main ToolMate AI message chain.\n\n# Requirement\n\nInstall `fabric` first! Read https://github.com/danielmiessler/fabric\n\n# How does the integration work?\n\nThe integration works with the tools `@command` and `@append_command` in ToolMate AI\n\n`@command` Execute the given command\n\n`@append_command` Append assistant previous response to the given command and execute.\n\nIn plugin `fabric.py`, two aliases are created:\n\n`@fabric` -> `@command fabric`\n\n`@append_fabric` -> `@append_command fabric`\n\nVersion 0.2.91 added config item `fabricPath`.  Users can customise fabric path by editing its value in `config.py`.\n\nRead more about system command integration at system command integration at https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/System%20Command%20Integration.md\n\n# Differences between Running Fabric via FreGenius AI and Running Fabric Alone\n\nThere are three major differences:\n\n1. ToolMate AI work with both text generation and task execution.  Running fabric alone chains up mainly generated texts. With ToolMate AI, text generated by fabric and work with a wider scope of AI tools. `fabric` weaves text together but `ToolMate AI` chains up both texts and actions.\n\n2. Visual text output\n\nThough you may run fabric alone in terminal, like:\n\n```\nfabric -p write_essay \"What is machine learning?\" | fabric -p extract_wisdom | fabric -p summarize\n```\nText output in intermediate steps are not visible. You can, however, visual all text-output by running fabric with ToolMate AI, e.g.:\n\n```\n@fabric -m gemini-1.5-pro -p write_essay \"What is machine learning?\"\n@append_fabric -m llama3.1:latest -p extract_wisdom\n@append_fabric -m mistral-large:123b -p summarize\n```\n\n3. Auto-save and Searchable\n\nResults generated in ToolMate AI are auto-saved and searchable.\n\n4. Pattern Clues\n\nFreenGenius AI integrates all fabric patterns in input suggestions, so that users can select a pattern easily.  Take a look at the screenshot above."
  },
  "doc-ba0989f99f67e36841d81256bd100791": {
    "content": "# Function Calling Approach with Any LLMs\n\n![toolmate_ai_screenshot](https://github.com/eliranwong/toolmate/assets/25262722/1e9dd18e-aa4b-4e2c-8d76-386af7ba00ea)\n\nCurrently, [LetMeDoIt AI](https://github.com/eliranwong/letmedoit) core features heavily reply on the strengths of OpenAI function calling features, which offer abilities:\n\n- to organize structured data from unstructured query\n- to accept multiple functions in a single guery\n- to automatically choose an appropriate function from numerouse available functions specified, by using the \"auto\" option.\n\nChallenges in Using Function Calling Features Without an OpenAI API Key:\n\n- Many popular open-source AI models lack support for function calling capabilities.\n- Utilizing function calling with these open-source models often demands high-end hardware to ensure smooth and timely operation.\n- Although a limited number of models, including Gemini Pro and certain open-source options, do offer function calling, their capacity is significantly limited, typically handling only one function at a time. This limitation places them well behind the advanced functionality of OpenAI, which can intelligently and efficiently select from multiple user-specified functions in a single request.\n- In our exploratory research and tests, we discovered [a viable workaround](https://medium.com/11tensors/connect-an-ai-agent-with-your-api-intel-neural-chat-7b-llm-can-replace-open-ai-function-calling-242d771e7c79). This method, however, is practical only for those willing to endure a wait of approximately 10 minutes [on a 64GB RAM device without GPU] for the execution of even a simple single task when numerous functions are specified simultaneously.\n\nIn essence, no existing solution matches the capabilities of OpenAI's function calling feature. There is a clear need for an innovative and efficient method to implement function calling features with open-source models on standard hardware. After extensive experimentation and overcoming numerous challenges, the author has developed a new approach:\n\nThis novel strategy involves breaking down the function calling process into several distinct steps for multiple generations:\n\n1. Intent Screening via [Tool Selection Agent](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Tool%20Selection%20Configurations.md)\n2. Tool Selection via [Tool Selection Agent](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Tool%20Selection%20Configurations.md)\n3. Retrival of Structured Data\n4. Tool Execution\n5. Chat Extension\n\nThis methodology has been found to work effectively with freely available open-source models, even on devices lacking a GPU.\n\nIn case you are interested, you may check, for example, [how we implement this approach with Llama.cpp](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/utils/call_llamacpp.py)\n\nWe invite [further discussion and contributions](https://github.com/eliranwong/toolmate/issues) to refine and enhance this strategy."
  },
  "doc-c50af8283bd4051d75176ccdda0b2c21": {
    "content": "# Workflows\n\nWorkflows are designed to save you from typing the frequently used actions repetitively.  Workflow is also a good way to share your collaborators or increase portability.\n\nSimply save your frequently used actions in a plain text file and call it with tool `@workflow`\n\n# File Format\n\nAny plain text files are supported.  For example, you can simply save your workflow in a plain text `*.txt` file.\n\n# How to use it?\n\nFor an example:\n\n1. Save the following content in a plain text file, named `my_workflow` in home directory:\n\n```\n@paste_from_clipboard\n@improve_writing\n@copy_to_clipboard\n```\n\n2. Run in ToolMate AI prompt:\n\n```\n@workflow ~/my_workflow\n```\n\nTips: you may simply drag the file to the terminal to get its path.\n\n# More\n\n## Use relative paths\n\nYou can use relative paths, by placing your workflow files in directory \"~/toolmate/workflows\", and run, for example:\n\n```\n@workflow my_workflow\n```\n\n## Nested workflows\n\nYou can insert your workflows in the middle of another workflow, e.g.:\n\n```\n@chat Hi\n@workflow my_workflow\n@chat give me a summary\n```"
  },
  "doc-091fd1c2512aeedbb720eae6434cc6cb": {
    "content": "# Plugins - Run Codes with Specific Packages\n\nSome tasks can be accomplished by executing code using various packages. You have the option to specify a particular package in the plugins to run the code with your preferred package.\n\n# Example: Get Information about Dates and Times\n\nIn our plugin [dates and times](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/dates%20and%20times.py), we instruct LetMeDoIt AI to use package \"pendulum\" for retrieval of information about dates and times.\n\nParticularly, on line 23, we wrote \"Python code that integrates package pendulum to resolve my query ...\"\n\n```\nfrom letmedoit import config\nfrom letmedoit.utils.shared_utils import SharedUtil\n\ndef datetimes(function_args):\n    code = function_args.get(\"code\") # required\n    information = SharedUtil.showAndExecutePythonCode(code)\n    return information\n\nfunctionSignature = {\n    \"name\": \"datetimes\",\n    \"description\": f'''Get information about dates and times''',\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"code\": {\n                \"type\": \"string\",\n                \"description\": \"Python code that integrates package pendulum to resolve my query\",\n            },\n        },\n        \"required\": [\"code\"],\n    },\n}\n\nconfig.chatGPTApiFunctionSignatures.append(functionSignature)\nconfig.chatGPTApiAvailableFunctions[\"datetimes\"] = datetimes\n```\n\n# Example: Create Maps\n\nIn our plugin [create maps](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/create%20maps.py), we instruct LetMeDoIt AI to use package \"folium\" for map creation.\n\nParticularly, on line 31, we wrote \"Python code that integrates package folium to resolve my request. ...\"\n\n```\nfrom letmedoit import config\nfrom letmedoit.utils.shared_utils import SharedUtil\nimport re, os\n\ndef create_map(function_args):\n    code = function_args.get(\"code\") # required\n    information = SharedUtil.showAndExecutePythonCode(code)\n    htmlPattern = r\"\"\"\\.save\\([\"']([^\\(\\)]+\\.html)[\"']\\)\"\"\"\n    match = re.search(htmlPattern, code)\n    if match:\n        htmlFile = match.group(1)\n        os.system(f\"{config.open} {htmlFile}\")\n    elif information:\n        return information\n    return \"\"\n\nfunctionSignature = {\n    \"name\": \"create_map\",\n    \"description\": f'''Create maps''',\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"code\": {\n                \"type\": \"string\",\n                \"description\": \"Python code that integrates package folium to resolve my request. Greated maps are saved in html format\",\n            },\n        },\n        \"required\": [\"code\"],\n    },\n}\n\nconfig.chatGPTApiFunctionSignatures.append(functionSignature)\nconfig.chatGPTApiAvailableFunctions[\"create_map\"] = create_map\n```\n\n# More about LetMeDoIt AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-eba52398f6766e0a128b55af166a6bf8": {
    "content": "# Examples (selective only):\n\nToolMate AI Plugins allow you to acheive variety of tasks with simple words:\n\n* generate tweets\n\n> Post a short tweet about LetMeDoIt AI\n\n* analyze audio\n\n> transcribe \"meeting_records.mp3\"\n\n* search / analyze financial data\n\n> What was the average stock price of Apple Inc. in 2023?\n\n> Analyze Apple Inc's stock price over last 5 years.\n\n* search weather information\n\n> what is the current weather in New York?\n\n* search news\n\n> tell me the latest news about ChatGPT\n\n* search old conversations\n\n> search for \"joke\" in chat records\n\n* load old conversations\n\n> load chat records with this ID: 2024-01-20_19_21_04\n\n* connect a sqlite file and fetch data or make changes\n\n> connect /temp/my_database.sqlite and tell me about the tables that it contains\n\n* integrated Google PaLM 2 multiturn chat, e.g.\n\n> ask PaLM 2 to write an article about Google\n\n* integrated Google Codey multiturn chat, e.g.\n\n> ask Codey how to use decorators in python\n\n* execute python codes with auto-healing feature and risk assessment, e.g.\n\n> join \"01.mp3\" and \"02.mp3\" into a single file\n\n* execute system commands to achieve specific tasks, e.g.\n\n> Launch VLC player and play music in folder \"music_folder\"\n\n* manipulate files, e.g.\n\n> remove all desktop files with names starting with \"Screenshot\"\n\n> zip \"folder1\"\n\n* save memory, e.g.\n\n> Remember, my birthday is January 1st.\n\n* send Whatsapp messages, e.g.\n\n> send Whatsapp message \"come to office 9am tomorrow\" to \"staff\" group\n\n* retrieve memory, e.g.\n\n> When is my birthday?\n\n* search for online information when LM lacks information, e.g.\n\n> Tell me somtheing about ToolMate AI?\n\n* add google or outlook calendar events, e.g.\n\n> I am going to London on Friday. Add it to my outlook calendar\n\n* send google or outlook emails, e.g.\n\n> Email an appreciation letter to someone@someone.com\n\n* analyze files, e.g.\n\n> Summarize 'Hello_World.docx'\n\n* analyze web content, e.g.\n\n> Give me a summary on https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1171397/CC3_feb20.pdf \n\n* analyze images, e.g.\n\n> Describe the image 'Hello.png' in detail\n\n> Compare images insider folder 'images'\n\n* remove image background, e.g.\n\n> Remove image background of \"my_photo.png\"\n\n* create qrcode, e.g.\n\n> Create a QR code for the website: https://letmedoit.ai\n\n* create maps, e.g.\n\n> Show me a map with Hype Park Corner and Victoria stations pinned\n\n* create statistical graphics, e.g.\n\n> Create a bar chart that illustrates the correlation between each of the 12 months and their respective number of days\n\n> Create a pie chart: Mary £10, Peter £8, John £15\n\n* solve queries about dates and times, e.g.\n\n> What is the current time in Hong Kong?\n\n* solve math problem, e.g.\n\n> You have a standard deck of 52 playing cards, which is composed of 4 suits: hearts, diamonds, clubs, and spades. Each suit has 13 cards: Ace through 10, and the face cards Jack, Queen, and King. If you draw 5 cards from the deck, in how many ways can you draw exactly 3 cards of one suit and exactly 2 cards of another suit?  \n\n* pronounce words in different dialects, e.g.\n\n> read tomato in American English\n\n> read tomato in British English\n\n> read 中文 in Mandarin\n\n> read 中文 in Cantonese\n\n* download Youtube video files, e.g.\n\n> Download https://www.youtube.com/watch?v=CDdvReNKKuk\n\n* download Youtube audio files and convert them into mp3 format, e.g.\n\n> Download https://www.youtube.com/watch?v=CDdvReNKKuk and convert it into mp3\n\n* edit text with built-in or custom text editors, e.g.\n\n> Edit README.md\n\n* improve language skills, e.g. British English trainer, e.g.\n\n> Improve my writing according to British English style\n\n* convert text display, e.g. from simplified Chinese to traditional Chinese, e.g.\n\n> Translate your last response into Chinese\n\n* create images, e.g.\n\n> Create an app icon for \"LetMeDoIt AI\"\n\n* modify images, e.g.\n\n> Make a cartoon verion of image \"my_photo.png\"\n\n## Fetures with OpenAI API key ONLY\n\nCurrently, the following features work only with a valid OpenAI API key\n\n* create ai assistants based on the requested task, e.g.\n\n> create a team of AI assistants to write a Christmas drama\n\n> create a team of AI assistants to build a scalable and customisable python application to remove image noise"
  },
  "doc-832e0a03b330e77b1c4975ff8ff7fb0a": {
    "content": "# Tool Descriptions\n\nThis page content is generated on 17Sept2024.  For the latest information, simply enter `@` in the ToolMate AI prompt interface.\n\n# Available Tools\n\n@add_google_calendar_event @add_outlook_calendar_event @examine_audio_google @examine_audio_groq @examine_audio_openai @examine_audio_whisper @examine_files @examine_images_chatgpt @examine_images_gemini @examine_images_groq @examine_images_llamacpp @examine_images_ollama @examine_web_content @append_command @append_fabric @append_instruction @apps @ask_chatgpt @ask_codey @ask_gemini @ask_groq @ask_llama3_1 @ask_llamacpp @ask_llamacppserver @ask_o1 @ask_o1_mini @ask_ollama @ask_palm2 @ask_perplexica @ask_tavily @bible @build_agents @chat @command @convert_relative_datetime @copy_to_clipboard @correct_python_code @create_image_dalle3 @create_image_flux @create_image_imagen3 @create_image_sd @create_map @create_qrcode @create_statistical_graphics @datetimes @deep_reflection @download_web_content @download_youtube_audio @download_youtube_video @edit_text @execute_computing_task @extract_bible_references @extract_python_code @fabric @files @general @help @images @improve_writing @install_python_package @it @list_current_directory_contents @load_conversations @lyrics @map @modify_images @music @news @open_browser @packages @paste_from_clipboard @qna @radio @read_aloud @recommend_tool @reflection @remove_image_background @repos @execute_python_code @save_memory @science @scientific_publications @search_conversations @search_finance @search_google @search_google_news @search_memory @search_searxng @search_sqlite @search_tavily @search_weather_info @send_gmail @send_outlook @send_tweet @social_media @software_wikis @translate @transcribe_audio_google @transcribe_audio_groq @transcribe_audio_openai @transcribe_audio_whisper @videos @web @wikimedia @workflow\n\n## Android-only tools:\n\n@show_location @show_connection @start_recording @stop_recording @phone_call @play_media @search_contacts @take_photo @selfie @read_sms @send_sms @send_email @send_whatsapp @share @share_file\n\n# Tips\n\nEnter `@` to get the latest descriptions of all available tools.\n\n# Descriptions\n\n`@add_google_calendar_event` Add a Google calendar event (Requirements: 'title', 'description', 'start_time', 'end_time')\n\n`@add_outlook_calendar_event` Add an Outlook calendar event (Requirements: 'title', 'description', 'start_time', 'end_time')\n\n`@examine_audio_google` Retrieve information from an audio with Google (Requirements: 'audio_filepath', 'language')\n\n`@examine_audio_groq` Retrieve information from an audio with Groq (Requirements: 'audio_filepath')\n\n`@examine_audio_openai` Retrieve information from an audio with OpenAI (Requirements: 'audio_filepath', 'language')\n\n`@examine_audio_whisper` Retrieve information from an audio with Whisper (Requirements: 'audio_filepath', 'language')\n\n`@examine_audio` Transcribe audio into text or retrieve information from an audio (Requirements: 'audio_filepath', 'language')\n\n`@examine_files` Retrieve information from files (Requirements: 'query', 'filepath')\n\n`@examine_images_chatgpt` Describe or compare images with ChatGPT (Requirements: 'query', 'image_filepath')\n\n`@examine_images_gemini` Describe or compare images with Gemini (Requirements: 'query', 'image_filepath')\n\n`@examine_images_groq` Describe or compare images with ChatGPT (Requirements: 'query', 'image_filepath')\n\n`@examine_images_llamacpp` Describe or compare images with Llama.cpp (Requirements: 'query', 'image_filepath')\n\n`@examine_images_ollama` Describe or compare images with Ollama (Requirements: 'query', 'image_filepath')\n\n`@examine_web_content` retrieve information from a webpage if an url is provided (Requirements: 'query', 'url')\n\n`@append_command` Execute a system command with the previous text output appended to it\n\n`@append_fabric` Execute a fabric command with the previous text output appended to it\n\n`@append_instruction` Append the previous text output to a given instruction\n\n`@apps` Search for information online in the 'apps' category.\n\n`@ask_chatgpt` Ask ChatGPT to chat or provide information (Requirements: 'query')\n\n`@ask_codey` Ask Codey for information about coding (Requirements: 'query')\n\n`@ask_gemini` Ask Gemini to chat or provide information (Requirements: 'query')\n\n`@ask_groq` Ask Groq to chat or provide information (Requirements: 'query')\n\n`@ask_llama3_1` Ask Llama3.1 to chat or provide information (Requirements: 'query')\n\n`@ask_llamacpp` Ask Llama.cpp to chat or provide information (Requirements: 'query')\n\n`@ask_llamacppserver` Ask Llama.cpp Server to chat or provide information (Requirements: 'query')\n\n`@ask_o1` Ask reasoning model o1 to chat or provide information (Requirements: 'query')\n\n`@ask_o1_mini` Ask reasoning model o1-mini to chat or provide information (Requirements: 'query')\n\n`@ask_ollama` Ask an Ollama model to chat or provide information (Requirements: 'query')\n\n`@ask_palm2` Ask PaLM 2 to chat or provide information (Requirements: 'query')\n\n`@ask_tavily` Ask internet to provide information (Requirements: 'query')\n\n`@bible` Show bible verses content\n\n`@build_agents` build a group of AI assistants or agents to execute a complicated task that other functions cannot resolve (Requirements: 'task', 'title')\n\n`@chat` Provide information or answer a question (Requirements: 'message')\n\n`@command` Execute a system command\n\n`@convert_relative_datetime` Convert relative dates and times in a given instruction to absolute dates and times\n\n`@copy_to_clipboard` Copy a given content to the system clipboard\n\n`@correct_python_code` Fix Python code if both the original code and the traceback error are provided (Requirements: 'code', 'missing_module', 'issue')\n\n`@create_image_dalle3` Create an image with DALLE-3 (Requirements: 'prompt')\n\n`@create_image_flux` Create an image with Stable Diffusion Models (Requirements: 'prompt')\n\n`@create_image_imagen3` Create an image with Imagen 3 (Requirements: 'prompt')\n\n`@create_image_sd` Create an image with Stable Diffusion Models (Requirements: 'prompt')\n\n`@create_map` Create maps (Requirements: 'code')\n\n`@create_qrcode` Create QR code (Requirements: 'url', 'text')\n\n`@create_statistical_graphics` Create statistical plots, such as pie charts or bar charts, to visualize statistical data (Requirements: 'code')\n\n`@datetimes` Get information about dates and times (Requirements: 'code')\n\n`@deep_reflection` Think and reason through a query, review and refine a response in detail\n\n`@download_web_content` Download file from internet (Requirements: 'url')\n\n`@download_youtube_audio` Download Youtube audio into mp3 file (Requirements: 'url')\n\n`@download_youtube_video` Download Youtube video into mp4 file (Requirements: 'url')\n\n`@edit_text` Edit text files with extensions: '*.txt', '*.md', '*.py'. (Requirements: 'filename')\n\n`@execute_computing_task` Execute computing task or gain access to device information (Requirements: 'code', 'title', 'risk')\n\n`@extract_bible_references` Extract Bible references from a block of text\n\n`@extract_python_code` Extract the python code in a given content\n\n`@fabric` Execute a fabric command\n\n`@files` Search for information online in the 'files' category.\n\n`@general` Search for information online in the 'general' category.\n\n`@help` Retrieve information from the documentation regarding how to use ToolMate AI (Requirements: 'query')\n\n`@images` Search for information online in the 'images' category.\n\n`@improve_writing` Improve the writing of a given content\n\n`@install_python_package` Install a python package (Requirements: 'package')\n\n`@it` Search for information online in the 'it' category.\n\n`@list_current_directory_contents` List the contents in the current directory\n\n`@load_conversations` Load a saved conversations if chat ID / timestamp / file path is given (Requirements: 'id')\n\n`@lyrics` Search for information online in the 'lyrics' category.\n\n`@map` Search for information online in the 'map' category.\n\n`@modify_images` Modify images with ChatGPT and DALLE-3 (Requirements: 'image_fullpath', 'requested_changes_in_detail')\n\n`@music` Search for information online in the 'music' category.\n\n`@news` Search for information online in the 'news' category.\n\n`@open_browser` Open https:// url with web browser (Requirements: 'url')\n\n`@packages` Search for information online in the 'packages' category.\n\n`@paste_from_clipboard` Retrieve the text content from the system clipboard and paste\n\n`@qna` Search for information online in the 'questions_and_answers' category.\n\n`@radio` Search for information online in the 'radio' category.\n\n`@read_aloud` Pronounce words or sentences with text-to-speech utility\n\n`@recommend_tool` Recommand an appropriate tool in response to a given request\n\n`@reflection` Think and reason through a query, review and refine a response\n\n`@remove_image_background` Remove image background (Requirements: 'filepath')\n\n`@repos` Search for information online in the 'repos' category.\n\n`@execute_python_code` Extract and run the python code in a given content\n\n`@save_memory` Use this function if I mention something which you think would be useful in the future and should be saved as a memory. Saved memories will allow you to retrieve snippets of past conversations when needed. (Requirements: 'memory', 'title', 'type', 'tags')\n\n`@science` Search for information online in the 'science' category.\n\n`@scientific_publications` Search for information online in the 'scientific_publications' category.\n\n`@search_conversations` Search chat records or conversations (Requirements: 'query')\n\n`@search_finance` Search or analyze financial data. Use this function ONLY WHEN package yfinance is useful to resolve my request (Requirements: 'code')\n\n`@search_google` Search Google for real-time information or latest updates when LLM lacks information (Requirements: 'keywords')\n\n`@search_google_news` Search the latest news with given keywords (Requirements: 'keywords')\n\n`@search_memory` Recall memories of important conversation snippets that we had in the past. (Requirements: 'query')\n\n`@search_searxng` Perform online searches to obtain the latest and most up-to-date, real-time information (Requirements: 'query')\n\n`@search_sqlite` Search or manage SQLite file, e.g. fetch data, update records, etc. Remember, use this function ONLY IF I provide you with a sqlite file path. (Requirements: 'path', 'request')\n\n`@search_tavily` Search for online information with Tavily (Requirements: 'query')\n\n`@search_weather_info` Answer a query about weather (Requirements: 'code')\n\n`@send_gmail` Send Gmail (Requirements: 'email', 'subject', 'body')\n\n`@send_outlook` Send Outlook email (Requirements: 'email', 'subject', 'body')\n\n`@send_tweet` Send a tweet to twitter (Requirements: 'message')\n\n`@social_media` Search for information online in the 'social_media' category.\n\n`@software_wikis` Search for information online in the 'software_wikis' category.\n\n`@translate` Search for information online in the 'translate' category.\n\n`@videos` Search for information online in the 'videos' category.\n\n`@web` Search for information online in the 'web' category.\n\n`@wikimedia` Search for information online in the 'wikimedia' category.\n\n`@transcribe_audio_google` Transcribe audio into text with Google (Requirements: 'audio_filepath', 'language')\n\n`@transcribe_audio_groq` Transcribe audio into text with Groq (Requirements: 'audio_filepath')\n\n`@transcribe_audio_openai` Transcribe audio into text with OpenAI (Requirements: 'audio_filepath', 'language')\n\n`@transcribe_audio_whisper` Transcribe audio into text with Whisper (Requirements: 'audio_filepath', 'language')\n\n`@workflow` Execute a workflow"
  },
  "doc-a5078e9e86ba4cecbc3efeb6fa89a54a": {
    "content": "# Edit config.py\n\nYou can edit any configuration value by manually editing the `config.py`, located in ToolMate AI directory.\n\n1. Make sure you know what and how to edit.  Invalid entries can break the startup process.  In case anything goes wrong with the file, delete it and restart ToolMate AI.\n\n2. Make sure ToolMate AI app is closed when you manually edit `config.py` with third-party text-editor.  If you want to edit the file while you are running the app, enter `.editconfigs` in ToolMate AI prompt."
  },
  "doc-dad16b6d840b701bfbd9920d6560fe83": {
    "content": "# How to Write a Function Call Plugin - Step-by-step Guide\n\nThis is a step-by-step guide to demonstrate how to write a custom LetMeDoItAI plugin that supports function calling for task execution.\n\nYou may refer to our original post at https://github.com/eliranwong/letmedoit/issues/31\n\n# Decide what you want to do with the plugin\n\nIn this demonstration, I am going to show you how to develop a LetMeDoIt AI plugin to check the latest news about anything.\n\n# STEP 1 - Research\n\nTo research about how to perform the task for searching the latest news, I used LetMeDoIt AI to ask Codey to provide me with related information.\n\nIn LetMeDoIt prompt, I entered:\n\n> Ask Codey how to check the latest news in my area, for example, London, UK, with python?\n\nI got the following response:\n\n```python\nimport feedparser\n\n# Get the latest news from a specific RSS feed\nfeed_url = \"https://news.google.com/rss/search?q=London+UK&hl=en-US&gl=US&ceid=US:en\"\nfeed = feedparser.parse(feed_url)\n\n# Print the title and link of each news item\nfor entry in feed.entries:\n    print(entry.title)\n    print(entry.link)\n```\n\n# STEP 2 - Develop a Function Method for Task Execution\n\nI need to develop a function method that accepts keywords as argument for searching the latest news.\n\nBased on the research in Step 1 above, the url for searching the news is:\n\n> \"https://news.google.com/rss/search?q=London+UK&hl=en-US&gl=US&ceid=US:en\"\n\nI observed two things:\n\n1. Two keywords \"London\" and \"UK\" placed between \"q=\" and \"&\"\n2. The keywords are connected with a \"+\" sign\n\nTherefore, I modified the code and developed a simple function method below that can accept a list for keywords for searching the latest news:\n\n```\nimport feedparser\n\n# Get the latest news from a specific RSS feed\ndef search_news(keywords: str) -> None:\n    feed_url = f\"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en\"\n    feed = feedparser.parse(feed_url)\n\n    # Print the title and link of each news item\n    for entry in feed.entries:\n        print(entry.title)\n        print(entry.link)\n```\n\n# STEP 3 - Develop a Function Signature\n\nAs I want LetMeDoIt AI to extract the keywords from user input, which is natural language, I need to develop a function signature to work with ChatGPT model that supports [function calling](https://platform.openai.com/docs/guides/function-calling).\n\nI decided that I need only one variable in the signature, i.e. keyword\n\nBelow is the signature that I prepared for the plugin:\n\n```\nfunctionSignature = {\n    \"name\": \"search_news\",\n    \"description\": \"Search the latest news with given keywords\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"keywords\": {\n                \"type\": \"string\",\n                \"description\": \"The keywords for searching the latest news, delimited by plus sign '+'.  For example, return 'London+UK' if keywords are 'London' and 'UK'.\",\n            },\n        },\n        \"required\": [\"keywords\"],\n    },\n}\n```\n\n# STEP 4 - Integration into LetMeDoIt AI\n\nAdd the following lines to the plugin.  You may read the self-explanatory comments in this snippet.\n\n```\n# The following line integrate the function method and signature into LetMeDoIt AI\nconfig.addFunctionCall(name=\"search_news\", signature=functionSignature, method=search_news)\n\n# The following line is optional. It adds an input suggestion to LetMeDoIt AI user input prompt\nconfig.inputSuggestions.append(\"Tell me the latest news about \")\n```\n\n# STEP 5 - Modify the Task Execution Method\n\nIn this step, I modified the task execution method I developed in STEP 2.\n\nAs LetMeDoIt AI passes all arguments to the called function as a dictionary, I made the following changes:\n\n1. change the argument type to dictionary and name the argument as \"function_args\".\n2. add a line, the first line, in the method to get the string \"keywords\" from the dictionary \"function_args\".\n3. Return an empty string to tell LetMeDoIt AI not to generate a follow-up response after the method is executed.\n\n```\nimport feedparser\n\n# Get the latest news from a specific RSS feed\ndef search_news(function_args: dict) -> str:\n    keywords = function_args.get(\"keywords\")\n    feed_url = f\"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en\"\n    feed = feedparser.parse(feed_url)\n\n    # Print the title and link of each news item\n    for entry in feed.entries:\n        print(entry.title)\n        print(entry.link)\n    return \"\"\n```\n\nIn this example, I make it simple to print all the information when the function method \"search_news\" is called and return an empty string.\n\nDepending on what you want, you can finish the function method differently.  For example, if you want to pass the retrieved information to ChatGPT to generate a response based on the retrieved information, instead of printing all information directly, you can modify the method like this one below:\n\n```\nimport feedparser, json\n\n# Get the latest news from a specific RSS feed\ndef search_news(function_args: dict) -> str:\n    keywords = function_args.get(\"keywords\")\n    feed_url = f\"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en\"\n    feed = feedparser.parse(feed_url)\n\n    # Pass the retrieved information to ChatGPT to generate a further response\n    info = {}\n    for index, entry in enumerate(feed.entries):\n        info[f\"news {index}\"] = {\n            \"title\": entry.title,\n            \"link\": entry.link,\n        }\n    return json.dumps(info)\n```\n\nRead more at https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Function-Calling#returning-function-call-response-to-chatgpt\n\n# STEP 6 - Fine Tune Text Display Style [OPTIONAL]\n\nThis step is optional.  I modified the function method further to display the information with print methods shared in object \"config\". In object \"config\", method \"print\" supports word wrap feature, and method \"print2\" print all content in color. In this modified method, each entry is divided by \"config.divider\".  \"config.stopSpinning\" is added to stop spinning before displaying retrieved information. In addition, I limit the results up to 10 entries.\n\n```\nfrom letmedoit import config\nimport feedparser\n\n# Get the latest news from a specific RSS feed\ndef search_news(function_args: dict) -> str:\n    keywords = function_args.get(\"keywords\")\n    feed_url = f\"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en\"\n    feed = feedparser.parse(feed_url)\n\n    # Print the title and link of each news item\n    config.stopSpinning()\n    config.print2(config.divider)\n    for index, entry in enumerate(feed.entries):\n        if index < 10:\n            if not index == 0:\n                config.print2(config.divider)\n            config.print(entry.title)\n            print(entry.link)\n    config.print2(config.divider)\n    return \"\"\n```\n\n# STEP 7 - Save the Plugin\n\n1. Open a text editor\n2. Save the following content with a filename \"search news.py\" in \"\\~/letmedoit/plugins\"\n\nRemarks:\n* \"\\~/letmedoit/plugins\" is the default storage directory for custom plugins\n* You may change the storage directory via [LetMeDoIt action menu](https://github.com/eliranwong/letmedoit/wiki/Action-Menu)\n\n```\nfrom letmedoit import config\nimport feedparser\n\n# Function method to get the latest news from a specific RSS feed\ndef search_news(function_args: dict) -> str:\n    keywords = function_args.get(\"keywords\")\n    feed_url = f\"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en\"\n    feed = feedparser.parse(feed_url)\n\n    # Print the title and link of each news item\n    config.stopSpinning()\n    config.print2(config.divider)\n    for index, entry in enumerate(feed.entries):\n        if index < 10:\n            if not index == 0:\n                config.print2(config.divider)\n            config.print(entry.title)\n            print(entry.link)\n    config.print2(config.divider)\n    return \"\"\n\n# Function signature to work with ChatGPT function calling\nfunctionSignature = {\n    \"name\": \"search_news\",\n    \"description\": \"Search the latest news with given keywords\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"keywords\": {\n                \"type\": \"string\",\n                \"description\": \"The keywords for searching the latest news, delimited by plus sign '+'.  For example, return 'London+UK' if keywords are 'London' and 'UK'.\",\n            },\n        },\n        \"required\": [\"keywords\"],\n    },\n}\n\n# The following line integrate the function method and signature into LetMeDoIt AI\nconfig.addFunctionCall(name=\"search_news\", signature=functionSignature, method=search_news)\n\n# The following line is optional. It adds an input suggestion to LetMeDoIt AI user input prompt\nconfig.inputSuggestions.append(\"Tell me the latest news about \")\n```\n\n# STEP 8 - Preparation for Testing\n\nCheck if your plugin's dependencies are installed with LetMeDoIt AI package by default at https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/requirements.txt\n\nIf not, activate your LetMeDoIt AI environment and install dependencies.\n\nIn this case, I install package \"feedparser\", run in terminal:\n\n> cd \\~/apps/letmedoit/bin/activate\n\n> pip install feedparser\n\nRemarks: \"\\~/apps/letmedoit\" is where I set up an environment for installing LetMeDoIt AI on our tested device.\n\n# STEP 9 - Testing\n\nI launched LetMeDoIt AI and entered the following prompt:\n\n> Give me the latest news about ChatGPT\n\nBelow is the screenshot of the result.\n\n![search_news](https://github.com/eliranwong/letmedoit/assets/25262722/f1741462-bc67-4171-8604-fa3d17c55762)\n\n# STEP 10 - Share Your Plugin With Other Users [OPTIONAL]\n\nAll plugins that shared with other users are made available at:\n\nhttps://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/\n\nTo share your plugin with other users, submit a pull request to our repository at:\n\nhttps://github.com/eliranwong/letmedoit/\n\nI finally uploaded this example plugin to:\n\nhttps://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/search%20latest%20news.py\n\n# Read more\n\nAbout LetMeDoIt AI plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview\n\nAbout LetMeDoIt AI Plugins that support Function Calling\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Function-Calling"
  },
  "doc-aca3060dd803974c1b7662f780fc795b": {
    "content": "# Additional Chat Model\n\nToolMate AI supports use of additional chat model with some backends: llama.cpp, llama.cpp server, ollama, groq.\n\nAdditional Chat Model is loaded for giving response when you use plugins `ask groq`, `ask ollama`, `ask llamacpp` and `ask llamacppserver`.\n\nFor example, when you use `ask ollama` plugin:\n\n* with additional chat model enabled, the selected additional model is loaded for answering your questions.\n\n* with additional chat model disabled, the main tool model is loaded for answering your questions."
  },
  "doc-d8ead668718b74679a8edf65563b0c9a": {
    "content": "# Installation\n\nFor Windows / macOS / LinuX / ChromeOS users:\n\n> pip install --upgrade toolmate\n\nFor Android users ([read more](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Termux%20Setup.md)):\n\n> pip install --upgrade toolmate_lite\n\nRemarks: In the first run, `Toolmate AI` automatically creates a directory `~/toolmate`, where user content is stored.  Therefore, it is not recommended to install `Toolmate AI` in `~/toolmate`.\n\n## Optional Modules\n\n`gui` install additional GUI library for running gui system tray and experimental desktop assistant\n\n> pip install --upgrade toolmate[gui]\n\n`linux` install additional packages for Linux users, i.e. `flaml[automl]`, `piper-tts`, `pyautogen[autobuild]`\n\n> pip install --upgrade toolmate[linux]\n\n`bible` install additional libraries for working with bible tools\n\n> pip install --upgrade toolmate[bible]\n\n# An Example\n\nInstall ToolMate AI, by running:\n\nTo set up virtual environment (recommended):\n\n> mkdir -p ~/apps\n\n> cd ~/apps\n\n> python3 -m venv toolmate\n\n> source toolmate/bin/activate\n\nTo install:\n\n> pip install --upgrade toolmate\n\nTo run:\n\n> toolmate\n\nTo start up with a particular backend, you may use parameter `-b`, e.g.:\n\n> toolmate -b groq\n\nTo set up an alias:\n\n> echo \"alias toolmate=~/apps/toolmate/bin/toolmate\" >> ~/.bashrc\n\nRemarks: Auto-upgrade is supported in macOS and Linux versions, but not in Windows version.  Windows users need to manually upgrade to get the latest features.\n\n# Notes to Android Users\n\nhttps://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Termux%20Setup.md\n\n# Notes to Windows Users\n\nWindows may also need to install cmake, rust and Microsoft Visual C++ 14.0 or greater.\n\nFor more information, read: https://github.com/eliranwong/letmedoit/wiki/Installation#windows-users\n\n# Notes to ChromeOS Users\n\nEnable Linux container in your Chrome OS first\n\nhttps://github.com/eliranwong/ChromeOSLinux#turn-on-linux\n\nUse the Linux terminal to install `toolmate`"
  },
  "doc-28464f4aa1c6b9278b4f0f8e34f2bbf8": {
    "content": "## Download for Offline Use\n\nToolMate AI can work with downloaded LLMs without internet. Upon the initial launch of ToolMate AI, it will automatically download all necessary LLMs for core features and configure them for your convenience.\n\nAdditional featured models are automatically downloaded based on specific feature requests. For instance, the Whisper model is automatically downloaded for offline use when users request the transcription of an audio file.\n\nhttps://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Change%20AI%20Backends%20and%20Models.md\n\n# Download LLM in GGUF Format\n\nThere are several ways to download.\n\n1. Download from https://huggingface.co directly\n\n2. Automatically download when you configure models by running '.model' in ToolMate AI prompt\n\n3. Download via Ollama, with 'ollama pull' command, e.g. 'ollama pull mistral'\n\n4. Use a ToolMate built-in function to export Ollama models to ToolMate Directory to enhance portability:\n\n```\nsource toolmate/bin/activate\npython3 -c \"from toolmate import exportOllamaModels; exportOllamaModels()\"\n```\n\n![export_ollama_models](https://github.com/eliranwong/toolmate/assets/25262722/f20f2e2e-a201-47bf-9da5-e5f59f26a281)"
  },
  "doc-9a982ed63e47fd8c67dd946baa60e0a0": {
    "content": "# Quick Guide\n\n# Installation\n\nhttps://github.com/eliranwong/toolmate/wiki#Installation\n\n# Launch ToolMate AI\n\nDouble-click the desktop shortcut created when ToolMate is first launched.\n\nAlternately, run in terminal:\n\n> toolmate\n\nWhen virtual environment is applied, e.g.\n\n> source toolmate/bin/activate\n\n> toolmate\n\n# Prompt Interface\n\nSimply enter your request in the prompt interface.\n\n<img width=\"857\" alt=\"prompt\" src=\"https://github.com/eliranwong/letmedoit/assets/25262722/cbf63cf3-29ec-4c75-9c6f-b08f5ea4f5b1\">\n\n[Examples](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Examples.md)\n\n# CLI Options\n\n> toolmate -h\n\n# Quick Actions\n\n* Enter \"\" (blank entry) to change open action menu\n\n* Enter \".cancel\" or press \"ctrl+z\" to cancel\n\n* Enter \".exit\" or press \"ctrl+q\" to quit app or exit currently opened feature\n\n* Press \"ctrl+k\" to display keyboard shortcuts\n\n# Multiline Input\n\nYou can toggle between \"single-line\" and \"multi-line\" entry modes by pressing \"Escape+l\"\n\n\"Enter\" behave differently in these two entry modes.\n\nIn \"single-line\" entry mode, pressing \"Enter\" completes an entry whereas pressing \"Tab\" [configurable] starts a new line.\n\nIn \"multi-line\" entry mode, pressing \"Escape+Enter\" completes an entry whereas pressing \"Enter\" starts a new line.\n\nTo have more control over editing, you can also use our built-in text editor \"eTextEdit\" to edit your entry by pressing \"ctrl+e\".  After you finish editing, press \"ctrl+s\" to save and \"ctrl+q\" to return to ToolMate AI prompt.\n\n# Action Menu\n\nhttps://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Action%20Menu.md\n\n# How to Change AI Backends and Models?\n\nhttps://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Change%20AI%20Backends%20and%20Models.md\n\n# How to Set up Google or OpenAI Credentials? [Optional]\n\nhttps://github.com/eliranwong/toolmate/wiki#optional-setup\n\n# Work with Both Text Generation and Task Execution\n\nToolMate AI has a built-in tool-selection agent to select a tool for every single request, read the following link to tweak related settings.\n\n[Tool Selection Configurations](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Tool%20Selection%20Configurations.md)\n\n# Special Entries\n\nUse `@` to specify a tool, to bypass ToolMate built-in tool-selection process, e.g. \n\n```\n@execute_python_code Convert \"Hello.docx\" into pdf format\n```\n\nAvailable tools at the time of timeing are:\n\n@chat @paste_from_clipboard @improve_writing @convert_relative_datetime @copy_to_clipboard @append_instruction @command @append_command @fabric @append_fabric @list_current_directory_contents @extract_python_code @execute_python_code @search_google @add_google_calendar_event @add_outlook_calendar_event @examine_audio @examine_files @examine_images @examine_web_content @ask_chatgpt @ask_codey @ask_gemini @ask_groq @ask_llama3_1 @ask_llamacpp @ask_llamacppserver @ask_ollama @ask_palm2 @correct_python_code @build_agents @create_image @create_map @create_qrcode @create_statistical_graphics @datetimes @download_web_content @download_youtube_audio @download_youtube_video @edit_text @execute_computing_task @install_python_package @save_memory @search_memory @modify_images @open_browser @pronunce_words @remove_image_background @search_conversations @load_conversations @search_finance @search_news @search_sqlite @search_weather_info @send_gamil @send_outlook @send_tweet\n\nTips: Enter `@` to get input suggestions of available tools\n\nYou can also run multiple tools in a single request, read https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Running%20Multiple%20Tools%20in%20One%20Go.md\n\nShortcut entries that starts with `.`, read https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Action%20Menu.md\n\nTips: enter `.` to display related input suggestions\n\n# Developer Mode\n\nDeveloper mode offers python playground and some developer options for advanced users.\n\nhttps://github.com/eliranwong/letmedoit/wiki/Developer-Mode\n\n# Upgrade\n\nYou can manually upgrade by running:\n\n> pip install --upgrade toolmate\n\nYou can also enable [Automatic Upgrade Option](https://github.com/eliranwong/letmedoit/wiki/Automatic-Upgrade-Option)"
  },
  "doc-00384cff71b1ae137fc155ff097fc80a": {
    "content": "# Plugins - Predefined Contexts\n\nYou can customize predefined contexts by modifying 'config.predefinedContexts' with use of plugins.\n\nFor example:\n\n1. Save a python file, e.g. predefinedContexts.py, in folder \"plugins\".\n\n2. Add content, for example:\n\n```\nfrom letmedoit import config\n\nconfig.predefinedContexts[\"Introduction\"] = \"\"\"Write a introduction pertaining to the following content.\"\"\"\n\nconfig.predefinedContexts[\"Summary\"] = \"\"\"Write a summary pertaining to the following content.\"\"\"\n\n```\n\nYou may even use awesome prompts suggested at https://github.com/f/awesome-chatgpt-prompts \n\nFor example, in our plugin \"[awesome prompts](https://github.com/eliranwong/letmedoit/tree/main/pip/letmedoit/plugins/awesome%20prompts.py)\":\n\n```\nfrom letmedoit import config\n\n# examples from: https://github.com/f/awesome-chatgpt-prompts\n\nconfig.predefinedContexts[\"English Translator and Improver\"] = \"\"\"I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. [NO_FUNCTION_CALL]\"\n\"\"\"\n\nconfig.predefinedContexts[\"Spoken English Teacher\"] = \"\"\"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors. [NO_FUNCTION_CALL]\"\"\"\n\nconfig.predefinedContexts[\"Biblical Translator\"] = \"\"\"I want you to act as an biblical translator. I will speak to you in english and you will translate it and answer in the corrected and improved version of my text, in a biblical dialect. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, biblical words and sentences. Keep the meaning same. I want you to only reply the correction, the improvements and nothing else, do not write explanations. [NO_FUNCTION_CALL]\"\"\"\n```\n\n# More about LetMeDoIt AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-d624e06bb668cd8e8d75854e9a597164": {
    "content": "# What to Expect During the Initial Launch?\n\nUpon the initial launch of ToolMate AI, it will download all the essential large language models that you require and automatically configure them for you.\n\n![first_launch](https://github.com/eliranwong/toolmate/assets/25262722/c000f589-d122-433e-b89b-1936af031356)\n\n# Bypass Downloading Large-sized Model Files\n\nOn some low-end devices, you may prefer bypassing large file downloads, you may start specify an online backend to lanuch the app, e.g.:\n\n> toolmate -b groq"
  },
  "doc-f50283466db39cca794aea33c114b955": {
    "content": "# Chat Record Management\n\nAll conversation records are saveable, searchable and shareable.\n\n# Auto Saving\n\nAll conversation records are automatically saved in plain text formats, if the app exits properly.\n\nThe saved records are stored in directory `~/toolmate/chats/` by default, where `~` denotes your home directory.\n\n# Manual Saving\n\nTo make sure your current conversation is saved up to a certain point, either:\n\n* Run `.save` in ToolMate AI prompt ui.\n\nor \n\n* Select `save current conversation` via ToolMate AI action menu.\n\n# Save as ...\n\nYou can save a conversation with a custom name at a custom location. Either:\n\n* Run `.saveas` in ToolMate AI prompt ui.\n\nor \n\n* Select `save current conversation as ...` via ToolMate AI action menu.\n\n# Open a Saved Conversation\n\nThis is a practical feature that allows users to resume any previous conversations at any time..\n\n* Run `.open` in ToolMate AI prompt ui.\n\nor \n\n* Select `open a saved conversation` via ToolMate AI action menu.\n\nEnter a file name, if the record file is in your current directory.  Otherwise, enter the file path to open it.\n\n# Search Previous Conversations\n\nWith the plugin \"Search chat records\" enabled:\n\n* All chat records are automatically saved in vector database format, in addition to the plain text format mentioned above.\n* You can use tool `@search_conversations` to search your old conversations.\n* You can use tool `@load_conversations` to load an old conversation, by specifying a chat ID identified in search results.\n\n# Share Conversations\n\nYou can simply share the saved conversations in plain text format with others.  They can load them with ToolMate AI and continue the conversations.\n\n# Keep a Readable Copy\n\nTo save a more readable copy in plain text format, either:\n\n* Run `.export` in ToolMate AI prompt ui.\n\nor \n\n* Select `export current conversation` via ToolMate AI action menu.\n\nEnter a file name or path to expor the current conversation."
  },
  "doc-46dc95c8f139e15b02c4f72336590a07": {
    "content": "# Plugins - Integrate Text-to-speech Feature\n\nYou may write a plugin with integration text-to-speech feature.\n\nFor example,\n\n```\nfrom letmedoit.utils.tts_utils import TTSUtil\nTTSUtil.play(\"Hello!\")\nTTSUtil.play(\"你好！\", \"zh\")\n```\n\nRead our plugin \"pronunce words\" at\n\nhttps://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/pronounce%20words.py\n\n# More about LetMeDoIt AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-dc1d20d6cb489144b9f62fd9387d69e9": {
    "content": "# Customise Assistant Name Display\n\nFrom version: 0.2.54\n\n1. Enter '.editconfigs' in ToolMate prompt\n\n2. Edit the following items:\n\nappName\n\ntext2art_font1\n\ntext2art_font1\n\n3. Save and Exit the built-in editor\n\nRead available fonts at: https://github.com/sepandhaghighi/art"
  },
  "doc-9a7a626018212a6f7f1f885b79ab5ee3": {
    "content": "# Groq Cloud API Key\n\nGroq Cloud API Key allows you to have FREE access to [selected open source LLMs](https://console.groq.com/docs/models).\n\nAt the time of writing, use of Groq Cloud API is FREE.\n\n# Generate Groq API Key\n\n1. Go to https://console.groq.com/keys\n\n2. Log in with a registered account\n\n3. Click menu item \"API Keys\" on the left\n\n4. Click button \"Create API Key\"\n\n5. Enter a name, for example, \"toolmate\"\n\n6. Copy or make a note of the created API key\n\n![groq_api_key](https://github.com/eliranwong/toolmate/assets/25262722/d479ad5f-40b5-4d9b-a766-83db023ead1c)\n\n# Set Up Groq API Key in ToolMate AI\n\n1. Enter \".apikeys\" in ToolMate AI prompt\n\n2. Follow the dialog and enter your Groq API key(s)\n\n# Support Mulitple Groq API Keys\n\nToolMate AI supports use of multiple groq API keys.  API keys take turns for running inference.\n\nTo use multiple groq API keys, when you prompts entering Groq API key, enter a list of groq API keys, instead of a single key, e.g.\n\n```\n[\"groq_api_key_1\", \"groq_api_key_2\", \"groq_api_key_3\"]\n```"
  },
  "doc-f91125c5b4c1173bd1d4b78ead23b1a0": {
    "content": "# Configure Llama.cpp Server with GPU Acceleration\n\n![llamacpp_with_gpu_offloading_compressed](https://github.com/eliranwong/toolmate/assets/25262722/2d607fc1-e6b5-4c62-be14-325d73866fce)\n\nRun '.model' in ToolMate AI prompt and select 'llamacppserver' as LLM interface.  This option is designed for advanced users who want more control over the LLM backend, particularly useful for customisation like GPU acceleration.\n\nBasically, [compile your customised copy of llama.cpp](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#build) on your device and enter the server command in ToolMate AI configurations. It auto-starts the llama.cpp server when ToolMate AI starts.\n\n# Example - macOS\n\nOn MacOS, Metal is enabled by default. Using Metal makes the computation run on the GPU.  Therefore, compiling source is a simple one:\n\nTo compile llama.cpp from source:\n\n> cd ~\n\n> git clone https://github.com/ggerganov/llama.cpp\n\n> cd llama.cpp\n\n> make\n\nTo configure ToolMate AI:\n\n1. Run 'toolmate' in your environment\n\n2. Enter '.model' in ToolMate AI prompt.\n\n3. Follow the instructions to enter command line, server ip, port and timeout settings.\n\n<img width=\"729\" alt=\"Screenshot 2024-06-06 at 11 32 54\" src=\"https://github.com/eliranwong/toolmate/assets/25262722/5004662d-03db-4f5b-a770-d0f16996a03c\">\n\nTo briefly explain the server command line above:\n\n> ~/llama.cpp/llama-server --host 127.0.0.1 --port 8080 --threads $(sysctl -n hw.physicalcpu) --ctx-size 0 --chat-template chatml --parallel 2 --model ~/models/wizardlm2.gguf\n\n```\n--threads $(sysctl -n hw.physicalcpu): set the threads to the number of physical CPU cores\n--ctx-size: size of the prompt context (default: 0, 0 = loaded from model)\n--parallel 2: set number of slots for process requests to 2\n```\n\nFor more options:\n\n> cd llama.cpp\n\n> ./server -h\n\n# Example - Acceleration with AMD Integrated GPU\n\nInference result is roughly 1.5x faster.  Read https://github.com/eliranwong/MultiAMDGPU_AIDev_Ubuntu/blob/main/igpu_only/igpu_only.md\n\nTested device: Beelink GTR6 (Ryzen 9 6900HX CPU + integrated Radeon 680M GPU + 64GB RAM)\n\nFollowed https://github.com/eliranwong/MultiAMDGPU_AIDev_Ubuntu/blob/main/README.md for ROCm installation.\n\nEnvironment variables:\n\n```\nexport ROCM_HOME=/opt/rocm\nexport LD_LIBRARY_PATH=/opt/rocm/include:/opt/rocm/lib:$LD_LIBRARY_PATH\nexport PATH=$HOME/.local/bin:/opt/rocm/bin:/opt/rocm/llvm/bin:$PATH\nexport HSA_OVERRIDE_GFX_VERSION=10.3.0\n```\n\nCompile Llama.cpp from source:\n\n> cd ~\n\n> git clone https://github.com/ggerganov/llama.cpp\n\n> make GGML_HIPBLAS=1 GGML_HIP_UMA=1 AMDGPU_TARGETS=gfx1030 -j$(lscpu | grep '^Core(s)' | awk '{print $NF}')\n\nEnter full command line in ToolMate AI configurations as described in previous example:\n\n> ~/llama.cpp/llama-server --host 127.0.0.1 --port 8080 --threads $(lscpu | grep '^Core(s)' | awk '{print $NF}') --ctx-size 0 --chat-template chatml --parallel 2 --gpu-layers 999 --model ~/models/wizardlm2.gguf\n\nPlease note we used `--gpu-layers` in the command above. You may want to change the its value 33 to suit your case.\n\n```\n--gpu-layers: number of layers to store in VRAM\n```\n\n# Example - Acceleration with Multiple Discrete AMD GPUs\n\nTested on Ubuntu with Dual AMD RX 7900 XTX. Full setup notes are documented at https://github.com/eliranwong/MultiAMDGPU_AIDev_Ubuntu/blob/main/README.md\n\nCompile Llama.cpp from source:\n\n> cd ~\n\n> git clone https://github.com/ggerganov/llama.cpp\n\n> make GGML_HIPBLAS=1 AMDGPU_TARGETS=gfx1100 -j$(lscpu | grep '^Core(s)' | awk '{print $NF}')\n\nEnter full command line in ToolMate AI configurations as described in previous examples:\n\n> ~/llama.cpp/llama-server --host 127.0.0.1 --port 8080 --threads $(lscpu | grep '^Core(s)' | awk '{print $NF}') --ctx-size 0 --chat-template chatml --parallel 2 --gpu-layers 999 --model ~/models/wizardlm2.gguf\n\n# Example - Acceleration with Nvidia GPUs\n\nCompile Llama.cpp from source:\n\n> cd ~\n\n> git clone https://github.com/ggerganov/llama.cpp\n\n> make GGML_CUDA=1 -j$(lscpu | grep '^Core(s)' | awk '{print $NF}')\n\nEnter full command line in ToolMate AI configurations as described in previous examples:\n\n> ~/llama.cpp/llama-server --host 127.0.0.1 --port 8080 --threads $(lscpu | grep '^Core(s)' | awk '{print $NF}') --ctx-size 0 --chat-template chatml --parallel 2 --gpu-layers 999 --model ~/models/wizardlm2.gguf\n\n# Read more\n\nhttps://github.com/ggerganov/llama.cpp?tab=readme-ov-file#build"
  },
  "doc-95085e367fcd9e0a48c3c41642cf5c1a": {
    "content": "# Plugins - Add Aliases\n\nYou can add aliases using a simple plugin by modifying the `config.aliases` Python dictionary. In this dictionary, the keys represent the aliases, while the values correspond to the entries they are associated with.\n\n# Example\n\nIn our plugin \"[aliases](https://github.com/eliranwong/letmedoit/tree/main/package/letmedoit/plugins/aliases.py)\", we define two aliases \"!etextedit\", \"!autoassist\" to launch our built-in text editor and mini interactive chat built with [pyautogen](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiHqo-s1saCAxX0QUEAHePECb4QFnoECA4QAQ&url=https%3A%2F%2Fmicrosoft.github.io%2Fautogen%2Fdocs%2FGetting-Started%2F&usg=AOvVaw211hBMU7JxQ7ywTVeZg2iy&opi=89978449) respectively.\n\nWith this plugin enabled, entering \"!etextedit\" in LetMeDoIt AI launches our built-in text editor \"eTextEdit\".\n\n```\nfrom letmedoit import config\nimport sys, os\n\n# add python python to work with virtual environment\nif not config.isTermux:\n    # integrated AutoGen agents\n    config.aliases[\"!autoassist\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'autoassist.py')}\"\n    config.aliases[\"!automath\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'automath.py')}\"\n    config.aliases[\"!autoretriever\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'autoretriever.py')}\"\n    config.aliases[\"!autoteachable\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'autoteachable.py')}\"\n    config.aliases[\"!autobuilder\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'autobuilder.py')}\"\n    # integrated Google AI tools\n    config.aliases[\"!geminiprovision\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'geminiprovision.py')}\"\n    config.aliases[\"!geminipro\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'geminipro.py')}\"\n    config.aliases[\"!palm2\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'palm2.py')}\"\n    config.aliases[\"!codey\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'codey.py')}\"\n# integrated text editor\nconfig.aliases[\"!etextedit\"] = f\"!{sys.executable} {os.path.join(config.letMeDoItAIFolder, 'eTextEdit.py')}\"\n```\n\nRemarks:\n\n1) Use 'sys.executable', instead of 'python' or 'python3', to work with virtual environment.\n\n2) For similar aliases, e.g. \"geminiprovision\" and \"geminipro\", enter the longer one first.\n\n# More about LetMeDoIt AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-3a70ca192bc2713104ce41948a517ec8": {
    "content": "# CLI Options\n\nRun:\n\n> toolmate -h"
  },
  "doc-6da1144b98798d92d4d6efc29226e96a": {
    "content": "# Offline TTS - macOS\n\nToolMate v0.2.42+ integrates macOS built-in text-to-speech feature.\n\n# Setup\n\n1. Select \"change text-to-speech config\" from action menu\n\n2. Select \"Say\" from available tts options\n\n3. Select a voice\n\nRemarks: Make the selected voice is [downloaded](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Offline%20TTS%20-%20macOS.md#download-more-voices) on your device.\n\n4. Specify Speed\n\n5. Select \"toggle input audio\" from action menu, to enable / disable reading input text\n\n6. Select \"toggle output audio\" from action menu, to enable / disable reading output text\n\n# Download More Voices\n\n1. Launch \"Settings\" App\n\n2. Go to \"Accessibility\" > \"Live Speech\"\n\n<img width=\"827\" alt=\"mactts1\" src=\"https://github.com/eliranwong/toolmate/assets/25262722/4a69d42e-30df-4a42-ad3a-83fc67d664c9\">\n\n3. Go to \"Voice\" > \"Manage Voices\"\n\n<img width=\"765\" alt=\"mactts2\" src=\"https://github.com/eliranwong/toolmate/assets/25262722/fdca4fb3-4c31-4f18-ae6b-078bd209fda7\">\n\n4. Click the 'cloud' button, right next to the voice that you want, to start download.\n\n<img width=\"730\" alt=\"mactts3\" src=\"https://github.com/eliranwong/toolmate/assets/25262722/f567a13b-2830-419d-a8ce-2761cf417ec4\">"
  },
  "doc-539d4b679f0f83e910ef48330bd6c9be": {
    "content": "# Plugins - Work with Non-conversational Model\n\nLetMeDoIt AI main UI is based on conversational models, e.g. gpt-3, gpt-4.\n\nDevelopers can utilise [function calls in plugins](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Function-Calling) to work with non-conversational models.\n\n# For example - Generate Image with DALL-E-3\n\nIn our plugin \"[create images](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/create%20images.py)\", we utilise a function call to pass the prompt to work with DALL-E-3 for image generation.\n\n```\nfrom letmedoit import config\nimport json, openai, os\nfrom base64 import b64decode\nfrom letmedoit.utils.shared_utils import SharedUtil\nfrom openai import OpenAI\n\ndef generate_image(function_args):\n    prompt = function_args.get(\"prompt\") # required\n    try:\n        # get responses\n        #https://platform.openai.com/docs/guides/images/introduction\n        response = OpenAI().images.generate(\n            model=\"dall-e-3\",\n            prompt=f\"I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS:\\n{prompt}\",\n            size=\"1024x1024\",\n            quality=\"hd\", # \"hd\" or \"standard\"\n            response_format=\"b64_json\",\n            n=1,\n        )\n        # open image\n        #imageUrl = response.data[0].url\n        #jsonFile = os.path.join(config.taskWizAIFolder, \"temp\", \"openai_image.json\")\n        #with open(jsonFile, mode=\"w\", encoding=\"utf-8\") as fileObj:\n        #    json.dump(response.data[0].b64_json, fileObj)\n        imageFile = os.path.join(config.taskWizAIFolder, \"temp\", f\"{SharedUtil.getCurrentDateTime()}.png\")\n        image_data = b64decode(response.data[0].b64_json)\n        with open(imageFile, mode=\"wb\") as pngObj:\n            pngObj.write(image_data)\n        if config.terminalEnableTermuxAPI:\n            config.mainWindow.getCliOutput(f\"termux-share {imageFile}\")\n        else:\n            os.system(f\"{config.open} {imageFile}\")\n\n    except openai.APIError as e:\n        config.print(\"Error: Issue on OpenAI side.\")\n        config.print(\"Solution: Retry your request after a brief wait and contact us if the issue persists.\")\n    except openai.RateLimitError as e:\n        config.print(\"Error: You have hit your assigned rate limit.\")\n        config.print(\"Solution: Pace your requests. Read more in OpenAI [Rate limit guide](https://platform.openai.com/docs/guides/rate-limits).\")\n    except openai.APIConnectionError as e:\n        config.print(\"Error: Issue connecting to our services.\")\n        config.print(\"Solution: Check your network settings, proxy configuration, SSL certificates, or firewall rules.\")\n    except openai.AuthenticationError as e:\n        config.print(\"Error: Your API key or token was invalid, expired, or revoked.\")\n        config.print(\"Solution: Check your API key or token and make sure it is correct and active. You may need to generate a new one from your account dashboard.\")\n    except:\n        SharedUtil.showErrors()\n\nfunctionSignature = {\n    \"name\": \"generate_image\",\n    \"description\": \"create an image\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"prompt\": {\n                \"type\": \"string\",\n                \"description\": \"description about the image\",\n            },\n        },\n        \"required\": [\"prompt\"],\n    },\n}\n\nconfig.chatGPTApiFunctionSignatures.append(functionSignature)\nconfig.chatGPTApiAvailableFunctions[\"generate_image\"] = generate_image\n```\n\n# Related Post\n\n[Plugin - anaylze image](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Analyze-Images)\n\n# More about taskWiz AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-d61135b74eb809643c99a0be3a5586a8": {
    "content": "# Tavily API Setup\n\nTavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\n\n# Get a Tavily API Key\n\nLog in https://app.tavily.com/sign-in and get an API key.\n\n# Set Up Tavily API Key in ToolMate AI\n\n1. Enter \".apikeys\" in ToolMate AI prompt\n\n2. Follow the dialog and enter your Tavily API key(s)\n\n# Support Mulitple Groq API Keys\n\nToolMate AI supports use of multiple Tavily API keys.  API keys take turns for running inference.\n\nTo use multiple Tavily API keys, when you prompts entering Tavily API key, enter a list of Tavily API keys, instead of a single key, e.g.\n\n```\n[\"tavily_api_key_1\", \"tavily_api_key_2\", \"tavily_api_key_3\"]\n```"
  },
  "doc-59bcb3c8a095b78015ffb20b8805913d": {
    "content": "# Support Wide Range of Backends and Models\n\nToolMate AI is designed to support a wide range of backends and models.  Both free and paid, online and offline.  You can use ToolMate AI completely free and offline after initial setup.\n\n# Supported Backends and Models\n\nToolMate AI supports four interfaces: llamcpp, ollama, gemini, and chatgpt. It also maintains backward compatibility with LetMeDoIt AI in LetMeDoIt Mode. The configuration of the LLM Interface is determined by the value of config.llmInterface, which defaults to 'llamacpp'.\n\n* llamacpp - [Llama.cpp](https://github.com/ggerganov/llama.cpp) / [Hugging Face models](https://huggingface.co/) + [Ollama Hosted models](https://ollama.com/library)\n\n* llamacppserver - [Llama.cpp](https://github.com/ggerganov/llama.cpp) [server](https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md) / [Hugging Face models](https://huggingface.co/) + [Ollama Hosted models](https://ollama.com/library) - This option supports llama.cpp, [compiled from source](https://github.com/ggerganov/llama.cpp#build), with GPU acceleration. Read more at https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/GPU%20Acceleration%20with%20Llama_cpp%20server.md\n\n* ollama - [Ollama](https://ollama.com/) / [Ollama Hosted models](https://ollama.com/library)\n\n* groq - [Groq cloud api and model](https://console.groq.com/keys) / [Groq Hosted models](https://console.groq.com/docs/models)\n\n* gemini - [Google Vertex AI](https://cloud.google.com/vertex-ai) / [Gemini Pro & Gemini Pro Vision](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models)\n\n* chatgpt - [OpenAI API](https://platform.openai.com/) / [ChatGPT models](https://platform.openai.com/docs/models)\n\n* letmedoit - [LetMeDoIt mode](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/LetMeDoIt%20Mode.md) / [ChatGPT models](https://platform.openai.com/docs/models)\n\n## Open Source Models on Consumer Hardware\n\nEven on CPU-only devices, ToolMate AI works well with a wide range of tested LLMs, particularly [wizardlm2:7b](https://ollama.com/library/wizardlm2). Download [ollama](https://ollama.com/) so that you may select open source LLMs easily via ToolMate AI prompt.\n\nNote: Ollama hosted models work with both \"llamacpp\" and \"ollama\" interfaces.\n\nRead more for chainging models at: https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Change%20AI%20Backends%20and%20Models.md\n\nToolMate AI also integrates the following models to enhance its abilities.\n\n## Vision\n\nllamacpp, ollama & groq: Llava (offline)\n\ngemini: Gemini Pro Vision (online)\n\nchatgpt & letmedoit: ChatGPT-4 Vision (online)\n\nRemarks: Groq cloud currently does not support multimodal models. Other backends are used in this case.\n\n## Audio Analysis\n\nllamacpp, ollama & groq: OpenAI Whisper (offline)\n\ngemini: Google Cloud Speech-to-Text Service (online)\n\nchatgpt & letmedoit: Whisper (online)\n\nRemarks: Groq cloud currently does not support multimodal models. Other backends are used in this case.\n\n## Image Creation and Modification\n\nllamacpp, ollama, groq & gemini: stable-diffusion\n\ngemini: plan for imagen when imagen is open to public access\n\nchatgpt: dall-e-3\n\nRemarks: Groq cloud currently does not support multimodal models. Other backends are used in this case.\n\n## Voice Typing Options\n\n1. Google Speech-to-Text (Generic)\n2. Google Speech-to-Text (API)\n3. OpenAI Whisper (offline)\n4. OpenAI Whisper via [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) (offline)\n\n## Text-to-Option Options\n\n1. [Offline TTS](https://github.com/eliranwong/toolmate/wiki#offline-text-to-speech) - [Windows - wsay](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Offline%20TTS%20-%20Windows.md); [macOS - say](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Offline%20TTS%20-%20macOS.md); [Linux - piper](https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Offline%20TTS%20-%20Linux.md)\n2. Google Text-to-Speech (Generic)\n3. Google Text-to-Speech (API)\n4. Elevenlabs (API)\n5. Custom system commands"
  },
  "doc-93ddd8ad41905bb4e11714d30ecf4b1e": {
    "content": "# Plugins - Overview\n\nTailor LetMeDoIt AI to suit your unique needs and preferences. With support for Python plugins, you can extend and customize LetMeDoIt's functionalities. Build plugins that integrate with external services, automate repetitive tasks, or enhance specific features. The possibilities are endless, allowing you to create a truly personalized virtual assistant experience.\n\n# How to Create a Plugin?\n\n1. Write python code in a file\n\n2. Save the file in *.py extension\n\n3. Place the file in directory \"\\~/letmedoit/plugins\", where \"\\~\" is your home directory.\n\nLetMeDoIt AI executes enabled plugins when it starts and when plugin selection is changed.\n\n# How to Create a Plugin for Task Execution?\n\nThis is a step-by-step guide to demonstrate how to write a custom LetMeDoItAI plugin that supports function calling for task execution:\n\nhttps://github.com/eliranwong/letmedoit/wiki/How-to-Write-a-Custom-Plugin\n\n# How to Modify a Built-in Plugin?\n\nBuilt-in plugins are located in directory \"[plugins](https://github.com/eliranwong/letmedoit/tree/main/package/letmedoit/plugins)\" under package directory.\n\n1. Copy the original plugin from package folder and save a copy in directory \"\\~/letmedoit/plugins\"\n\n2. You may rename the plugins in \"\\~/letmedoit/plugins\"\n\n3. Modify the content of the file to suit your needs.\n\nFor example, you can copy plugin \"[ask gemma](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/ask%20gemma.py)\" to \"\\~/letmedoit/plugins\" and edit the model name from \"gemma:7b\" to \"gemma:2b\".\n\n# Enable / Disable Individual Plugins\n\n1. Enter a blank entry '' to launch action menu.\n\n2. Select \"change plugins\".\n\n3. Select / unselect individual plugins to enable / disable them.\n\n4. Select \"OK\" to make changes effective.\n\n<img width=\"859\" alt=\"enable_disable_plugins\" src=\"https://github.com/eliranwong/letmedoit/assets/25262722/14440c0b-f49b-4558-b712-caa08cb207a9\">\n\n# How does Plugins Work with LetMeDoIt AI?\n\nLetMeDoIt AI utilizes 'config' modules to interact with plugins. Developers can write plugins in Python to modify or add functionalities to LetMeDoIt AI by working with the following variables:\n\n* config.aliases [read more](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Add-Aliases)\n\n* config.inputSuggestions [read more](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Input-Suggestions)\n\n* config.outputTextConverters [read more](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Transform-Text-Output)\n\n* config.predefinedContexts [read more](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Predefined-Contexts)\n\n* config.addFunctionCall [read more](https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Function-Calling)\n\n# Enable a Plugin to Execute Task\n\nTo enable a plugin to execute a task, instead of generating text only, integrate function calling feature in the plugin.\n\nRead https://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Function-Calling\n\n# Install Additional Packages with Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Install-Additional-Packages\n\n# Work with LetMeDoIt AI Configurations\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Work-with-LetMeDoIt-AI-Configurations\n\n# Run Codes with Specific Packages\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Run-Codes-with-Specific-Packages\n\n# Work with Non-conversational Model\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Work-with-Non%E2%80%90conversational-Model\n\n# Integrate Text-to-speech Feature\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Integrate-Text%E2%80%90to%E2%80%90speech-Feature\n\n# Integrate Other Shared Utilities\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Integrate-Other-Shared-Utilities\n\n# Cookbook\n\nCheck our built-in plugins at https://github.com/eliranwong/letmedoit/tree/main/package/letmedoit/plugins"
  },
  "doc-a115146372569d0e13825dac3d3ab3a4": {
    "content": "# How to Change AI Backends and Large Language Models?\n\nEnter \".model\" in ToolMate AI prompt and follow the dialogs.\n\nAlternately, press the `ENTER` key to enter a blank entry, to launch the ToolMate AI action menu.  Choose `change AI backends and models` and click `Ok`.\n\n## Screenshots:\n\n![select_model_1](https://github.com/eliranwong/toolmate/assets/25262722/179cd040-b7c4-4592-b2b4-f152a9ec1772)\n\n![select_model_2](https://github.com/eliranwong/toolmate/assets/25262722/ff3f4b94-97e0-48f7-9e0d-49cf195321e8)\n\n![select_model_3](https://github.com/eliranwong/toolmate/assets/25262722/ad79f5c1-5bd8-480c-9428-5d1e704ee153)\n\n![select_model_4](https://github.com/eliranwong/toolmate/assets/25262722/0183c0ec-9c2c-484c-a2bf-4132fdbd343a)\n\n![select_model_5](https://github.com/eliranwong/toolmate/assets/25262722/b88f3950-a898-4fbf-8691-c4789caeb441)\n\n\n# Edit config.py manually\n\nYou can also edit manually the folloinwg values in config.py:\n\n(Remarks: Edit config.py only when the app is closed)\n\n## llmInterface\n\nYou can also manually edit the value of 'llmInterface' in config.py\n\nAccepted values: 'llamacpp',  'ollama', 'gemini', 'chatgpt\", \"letmedoit\"\n\nBelow are items related to individual backends.\n\n## llmInterface = 'llamacpp'\n\nCheck available *gguf models at: https://huggingface.co/\n\nThe most direct way is change \"*_model_path\" in config.py if model files are already in place:\n\n* llamacppToolModel_model_path\n\n* llamacppChatModel_model_path\n\nAlternately, to download and set modes, change:\n\n* llamacppToolModel_repo_id, e.g. 'TheBloke/phi-2-GGUF' (default), 'TheBloke/Llama-2-7B-Chat-GGUF', 'SinpxAI/Neural-Chat-7B-v3.3-GGUF', 'NousResearch/Hermes-2-Pro-Mistral-7B-GGUF', 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF'\n\n* llamacppToolModel_filename, e.g. 'phi-2.Q4_K_M.gguf' (default), 'llama-2-7b-chat.Q4_K_M.gguf', 'neural-chat-7b-v3.3.Q4_K_M.gguf', 'TheBloke/neural-chat-7B-v3-1-GGUF', 'Hermes-2-Pro-Mistral-7B.Q4_K_M.gguf', 'Nous-Hermes-2-Mixtral-8x7B-DPO.Q4_K_M.gguf'\n\n* llamacppChatModel_repo_id, e.g. 'TheBloke/phi-2-GGUF' (default), 'TheBloke/CodeLlama-7B-Python-GGUF'\n\n* llamacppChatModel_filename, e.g. 'phi-2.Q4_K_M.gguf' (default), 'codellama-7b-python.Q4_K_M.gguf'\n\nRemarks: match repo_id and filename reasonably that sepecified filename have to be available for download in the specified repo_id\n\n## llmInterface = 'ollama' \n\nCheck available models at: https://ollama.com/library\n\n* ollamaToolModel, e.g. 'phi' (default), 'mistral', 'llama2', e.g.\n\n* ollamaChatModel, e.g. 'phi' (default), 'codellama', 'starcoder2', e.g.\n\n## llmInterface = 'groq'\n\nEdit the value of 'groqApi_model'.  Its default value is 'mixtral-8x7b-32768''\n\n## llmInterface = 'gemini'\n\nCurrent available option is Google Gemini Pro\n\n## llmInterface = 'chatgpt'\n\nEdit the value of 'chatGPTApiModel'.  Its default value is 'gpt-4-turbo'\n\n## llmInterface = 'letmedoit'\n\nEdit the value of 'chatGPTApiModel'.  Its default value is 'gpt-4-turbo'"
  },
  "doc-6195ae51400d4ac8d053d22857a76ba0": {
    "content": "# Plugins - Input Suggestions\n\nInput suggestion feature provides automated suggestions or completions for user input based on the context.\n\n![integration_open_interpreter2](https://github.com/eliranwong/letmedoit/assets/25262722/4233b3c8-364e-466b-8218-c2dca7c134e5)\n\n# Customize it!\n\nYou can customize input suggestions by modifying 'config.inputSuggestions' with use of plugins.\n\nFor example:\n\n1. Save a python file, e.g. inputSuggestions.py, in folder \"plugins\".\n2. Add content, for example:\n\n```\nfrom letmedoit import config\n\nconfig.inputSuggestions = config.inputSuggestions + [\"Write a summary\", \"Write an outline\", \"Write a letter\"]\n```\n\nThis is exactly what we did in our plugin [input suggestions](https://github.com/eliranwong/letmedoit/tree/main/package/letmedoit/plugins/input%20suggestions.py).\n\n# More about LetMeDoIt AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-056c6520c1a091b8acec1393e2529bfe": {
    "content": "# Docker Setup on Android Termux\n\nThis page describe how to set up `docker` on Android via Termux.  It is a requirement for settting up Perplexica and SearXNG with which ToolMate AI plugins `search perplexica` and `search searxng` work.\n\n# Overview\n\nThe steps below installs a virtual machine of `alpine` in Termux.\n\nDocker and docker related service are set up inside the virtual machine.\n\nAndroid web browsers or ToolMate AI tools access the service via forwarded ports.\n\n# Preparation 1\n\nInstall Termux first!\n\nRead https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Termux%20Setup.md\n\n# Preparation 2\n\nCheck available free memory on your Android device, by running `free -h`.\n\n![memory_check](https://github.com/user-attachments/assets/f6364b94-8338-48a3-b216-f2b1f163a29b)\n\nYou may consider this piece of information when you assign memory to the virtual machine we are going to build.\n\n# Preparation 3\n\n1. Go to https://www.alpinelinux.org/downloads/\n2. Locate `x86_64` ander the `virtual` session.\n3. Long press on it and select `Copy link address`\n\nIn the following example the address is:\n\n> https://dl-cdn.alpinelinux.org/alpine/v3.20/releases/x86_64/alpine-virt-3.20.3-x86_64.iso\n\nWe will use this address in the following step.\n\n# Alpine Setup\n\n```\ncd\npkg update && pkg upgrade\npkg install wget qemu-system-x86-64-headless qemu-utils\nmkdir alpine\ncd alpine\nwget https://dl-cdn.alpinelinux.org/alpine/v3.20/releases/x86_64/alpine-virt-3.20.3-x86_64.iso\n```\n\nRemarks: In the last line above, we use the previous copied address.\n\n```\nqemu-img create -f qcow2 alpine.qcow2 10G\nqemu-system-x86_64 -m 512 -netdev user,id=n1,hostfwd=tcp::2222-:22,hostfwd=tcp::4000-:4000,hostfwd=tcp::3000-:3000,hostfwd=tcp::3001-:3001 -device virtio-net,netdev=n1 -nographic alpine.qcow2 -cdrom alpine-virt-*.iso\n```\n\nRemarks: \n\n1. You may adjust the memory assignment `-m 512`, depending on the available memory on your device that we previously checked, e.g. you may change it to `-m 1024` or `-m 2048`.\n\n2. Port `2222` from host is forwarded to the port `22` in the virtual machine for ssh access from the host.\n\n3. Ports `4000` is exposed for access to SearXNG server, that is to be installed later.\n\n4. Ports `3000` and `3001` are exposed for access to Perplexica frontend and backend servers, that are to be installed later.\n\n```\nmkdir -p /etc/udhcpc\necho 'RESOLV_CONF=\"no\"' >> /etc/udhcpc/udhcpc.conf\necho -e \"nameserver 8.8.8.8\\nnameserver 8.8.4.4\" >> /etc/resolv.conf\nsetup-alpine\n```\n\n![alpine_001](https://github.com/user-attachments/assets/a5ca574d-965e-49e2-a8b3-542da909a888)\n\nRemarks:\n\nFor most steps in the setup, you may simply press `enter` to use default value, except the following items:\n\n1. Enter a time zone when prompted.\n\n![alpine_003_time_zone](https://github.com/user-attachments/assets/404a95cd-acca-4920-bad2-0eee3f180ace)\n\n2. Enter `none` to question `Which NLP client to run?`\n\n![ntp_client](https://github.com/user-attachments/assets/a86ef5db-ca4d-42b1-9689-c8a441d5c421)\n\n3. Enter `yes` to question `Allow root ssh login?`\n\n4. Enter `sda` to question `Which disk(s) would you like to use?`\n\n5. Enter `sys` to question `How would you like to use it?`\n\n![alpine_setup_last_steps](https://github.com/user-attachments/assets/6bb78271-863e-456b-aec9-d9f703752a41)\n\n6. At the end, enter `y` to question `Erase the above disk(s) and continue?`\n\n```\npoweroff\nexit\n```\n\n# Docker Setup\n\nRestart:\n\n```\ncd\ncd alpine\nqemu-system-x86_64 -m 512 -netdev user,id=n1,hostfwd=tcp::2222-:22,hostfwd=tcp::4000-:4000,hostfwd=tcp::3000-:3000,hostfwd=tcp::3001-:3001 -device virtio-net,netdev=n1 -nographic alpine.qcow2\n```\n\nRemarks: Please note that the command line here does not contain `-cdrom alpine-virt-*.iso`.\n\nEdit repositories:\n\n```\nvi /etc/apk/repositories\n```\n\n![add_repository](https://github.com/user-attachments/assets/1f215cd5-efbf-4088-9577-b0027226a149)\n\n1. Press the `i` key, to enter the edit mode\n2. Navigate to the beginning of the line 3\n3. Uncomment the line by removing the `#` symbol\n4. Press the `ESC` key, to leave the edit mode\n5. Enter `:wq` to save the change and exit the editor\n\nInstall Docker and common tools:\n\n```\napk update\napk add docker docker-cli docker-compose py3-pip git wget curl\n```\n\nStart Docker:\n\n```\nservice docker start\n```\n\nTest Docker:\n\n```\ndocker run hello-world\n```\n\n# Install Perplexica and SearXNG\n\nInside the virtual machine:\n\n```\ncd\ngit clone https://github.com/ItzCrazyKns/Perplexica\ncd Perplexica\ncp sample.config.toml config.toml\nvi config.toml\n```\n\n![edit_perplexica_config](https://github.com/user-attachments/assets/340e71f1-4ea3-4048-839b-208c7c18abf8)\n\n![perplexica_config](https://github.com/user-attachments/assets/342a1996-0d8d-4959-85a2-a439861be1b8)\n\nSteps to edit:\n\n1. Press the `i` key, to enter the edit mode\n2. Navigate inside the quotes \"\" of API keys or Ollama url\n3. Long press to paste previously copied API keys or url\n4. Press the `ESC` key, to leave the edit mode\n5. Enter `:wq` to save the change and exit the editor\n\n```\ndocker compose up -d\n```\n\nWait until you see all the ticks, like below:\n\n![install_Perplexica](https://github.com/user-attachments/assets/7c831c15-1291-4417-8ceb-2eb5a3b4ef06)\n\nTest SearXNG with web browser:\n\n> http://localhost:4000\n\n![Screenshot_20241016-004429](https://github.com/user-attachments/assets/ad08f570-9004-4561-9d56-59ca555e3518)\n\nTest Perplexica with web browser:\n\n> http://localhost:3000\n\n![Screenshot_20241016-004411](https://github.com/user-attachments/assets/302401c5-1eac-4285-991f-ae97eae239bd)\n\nRemarks: It takes time the first time for the links to be loaded.  In our testings, Firefox browser loads faster than Chrome browser.\n\n# Integration of SearXNG and Perplexica with ToolMate AI\n\nRead https://github.com/eliranwong/toolmate/blob/main/package/toolmate/docs/Perplexica%20and%20SearXNG%20Integration.md\n\n# How to shutdown the virtual machine?\n\nRun in virtual machine:\n\n```\npoweroff\nexit\n```\n\n# How to restart the virtual machine?\n\nRun in Termux:\n\n```\nqemu-system-x86_64 -m 512 -netdev user,id=n1,hostfwd=tcp::2222-:22,hostfwd=tcp::4000-:4000,hostfwd=tcp::3000-:3000,hostfwd=tcp::3001-:3001 -device virtio-net,netdev=n1 -nographic alpine.qcow2\n```\n\n# How to start docker or perplexica after the virtual machine is launched?\n\nRun in virtual machine:\n\n```\nservice docker start\n```\n\nYou just need to set up Perplexica once.  When you run `service docker start`, it runs the Perplexica and SearXNG service too.\n\n# How to run ToolMate AI while the virtual machine is running?\n\nLong press the left edge of the Termux app and drag gently to the right, then you will see the panel where you can add a `NEW SESSION`.\n\nLaunch a `NEW SESSION` in which you may run ToolMate AI.\n\n![new_session](https://github.com/user-attachments/assets/3cc9f388-e878-45a6-9ba7-a846fa092c5d)\n\n# References\n\nhttps://github.com/P1N2O/qemu-termux-alpine\n\nhttps://github.com/cyberkernelofficial/docker-in-termux\n\nhttps://medium.com/@kumargaurav.pandey/vms-on-mobile-without-root-yes-please-f14f473deec7\n\nhttps://medium.com/@kumargaurav.pandey/docker-on-mobile-that-too-without-root-how-7b0848833c42"
  },
  "doc-897539890491f2e932f7864ee7373f84": {
    "content": "# Plugins - Function Calling\n\n[The function calling features of ChatGPT](https://platform.openai.com/docs/guides/function-calling) in LetMeDoIt AI make it very powerful because they allow you to execute various tasks and access a wide range of functionalities. Here are some ways in which these features make LetMeDoIt AI powerful:\n\n1. **System Commands**: You can use system commands to perform actions on your device, such as executing shell commands, managing files and directories, and interacting with the operating system. This gives you control over your device and allows you to automate tasks.\n\n2. **Python Code Execution**: With the ability to execute Python code, LetMeDoIt AI can perform complex computations, manipulate data, and interact with external libraries and APIs. This opens up a world of possibilities for data analysis, machine learning, web scraping, and more.\n\n3. **Plugin Integration**: You can extend the functionality of LetMeDoIt AI by adding plugins. These plugins can provide additional capabilities, such as searching the internet, accessing calendars, downloading media, editing text files, generating images, pronouncing words, sending emails, and more. This allows LetMeDoIt AI to assist you in a wide range of tasks and workflows.\n\n4. **Error Handling and Debugging**: If you encounter errors or issues while executing commands or code, LetMeDoIt AI can help you diagnose and fix them. It can analyze error messages, suggest solutions, and even automatically fix Python \ncode based on traceback errors.\n\n5. **Security and Risk Assessment**: Before executing potentially risky commands or code, LetMeDoIt AI can assess the risk level and inform you about the potential impacts. This helps you make informed decisions and avoid unintended consequences.\n\nOverall, the function calling features of ChatGPT in LetMeDoIt AI empower you to perform a wide range of tasks, automate workflows, access external resources, and leverage the power of Python programming. It combines the capabilities of a virtual assistant and a code execution environment, making it a powerful tool for both productivity and development purposes.\n\n# How to write a custom plugin that supports function calls?\n\n<b>[NEW]</b> We wrote a step-by-step guide to help you walk through the plugin development process:\n\nhttps://github.com/eliranwong/letmedoit/wiki/How-to-Write-a-Custom-Plugin\n\nEach function call plugin has four essential elements:\n\n1. Import statement of letmedoit config\n\n> from letmedoit import config\n\n2. A function method for task execution\n\n3. A function signature to communicate with ChatGPT about when to use the plugin and what arguments the arguments required by the function method\n\n4. Integration of the function method and the function signature into LetMeDoIt AI:\n\n* use shared method \"config.addFunctionCall\" for the integration\n\n# Example 1 - install python package\n\nOur plugin \"install python package\" install python package into the environment that runs LetMeDoIt AI upon users' request.  \n\nThis plugin is the simplest one among our built-in plugins. It contains the four basic elements we mentioned above:\n\n1. import statements to import letmedoit config object and to import the install method\n2. a function method to install a python package for users\n3. a function signature to communicate with ChatGPT about when to call the function method\n4. a single line to integrate the function method and signature into LetMeDoIt AI\n\n```\n# import statement\nfrom letmedoit import config\nfrom letmedoit.utils.install import installmodule\n\n# Function method\ndef install_python_package(function_args):\n    package = function_args.get(\"package\") # required\n    if package:\n        install = installmodule(f\"--upgrade {package}\")\n        return \"Installed!\" if install else f\"Failed to install '{package}'!\"\n    return \"\"\n\n# Function Signature\nfunctionSignature = {\n    \"name\": \"install_python_package\",\n    \"description\": f'''Install python package''',\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"package\": {\n                \"type\": \"string\",\n                \"description\": \"Package name\",\n            },\n        },\n        \"required\": [\"package\"],\n    },\n}\n\n# Integrate the signature and method into LetMeDoIt AI\nconfig.addFunctionCall(name=\"install_python_package\", signature=functionSignature, method=install_python_package)\n```\n\n# Example 2 - edit text\n\nIn our plugin \"[edit text](https://github.com/eliranwong/letmedoit/tree/main/package/letmedoit/plugins/edit%20text.py)\", we have a function signature named \"edit_text\" and a function method \"edit_text\". Function arguments, \"filename\" in this case, specified in the function signature are passed to the function method as a dictionary.\n\n```\nfrom letmedoit import config\nimport os, re, sys\nfrom letmedoit.utils.shared_utils import SharedUtil\n\n# persistent\n# users can customise 'textEditor' and 'textFileExtensions' in config.py\npersistentConfigs = (\n    #(\"textEditor\", \"micro -softwrap true -wordwrap true\"), # read options at https://github.com/zyedidia/micro/blob/master/runtime/help/options.md\n    (\"textFileExtensions\", ['txt', 'md', 'py']), # edit this option to support more or less extensions\n)\nconfig.setConfig(persistentConfigs)\n\nif config.customTextEditor:\n    textEditor = re.sub(\" .*?$\", \"\", config.customTextEditor)\n    if not textEditor or not SharedUtil.isPackageInstalled(textEditor):\n        config.customTextEditor = \"\"\n\ndef edit_text(function_args):\n    customTextEditor = config.customTextEditor if config.customTextEditor else f\"{sys.executable} {os.path.join(config.taskWizAIFolder, 'eTextEdit.py')}\"\n    filename = function_args.get(\"filename\") # required\n    # in case folder name is mistaken\n    if os.path.isdir(filename):\n        os.system(f\"\"\"{config.open} {filename}\"\"\")\n        return \"Finished! Directory opened!\"\n    else:\n        command = f\"{customTextEditor} {filename}\" if filename else customTextEditor\n        config.stopSpinning()\n        os.system(command)\n        return \"Finished! Text editor closed!\"\n\nfunctionSignature = {\n    \"name\": \"edit_text\",\n    \"description\": f'''Edit text files with extensions: '*.{\"', '*.\".join(config.textFileExtensions)}'.''',\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"filename\": {\n                \"type\": \"string\",\n                \"description\": \"Text file path given by user. Return an empty string if not given.\",\n            },\n        },\n        \"required\": [\"filename\"],\n    },\n}\n\nconfig.addFunctionCall(name=\"edit_text\", signature=functionSignature, method=edit_text)\n```\n\n# Example 3 - Working with Both Required and Optional Arguments\n\nIn our plugin \"[add calendar event](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/add%20calendar%20event.py)\", you can see there are both required and optional arguments specified in the function signature named \"add_calendar_event\". Required arguments are \"calendar\", \"title\", \"description\" and \"start_time\". Optional arguments are \"url\", \"end_time\" and \"location\". As all arguments are passed to the function method \"add_calendar_event\", developers can work with arguments with standard python dictionary methods.\n\n```\nfrom letmedoit import config\nimport datetime\nfrom letmedoit.utils.shared_utils import SharedUtil\nimport urllib.parse\n\ndef add_calendar_event(function_args):\n    calendar = function_args.get(\"calendar\") # required\n    title = function_args.get(\"title\") # required\n    description = function_args.get(\"description\") # required\n    url = function_args.get(\"url\", \"\") # optional\n    start_time = function_args.get(\"start_time\") # required\n    end_time = function_args.get(\"end_time\", \"\") # optional\n    location = function_args.get(\"location\", \"\") # optional\n\n    title = urllib.parse.quote(title)\n    description = urllib.parse.quote(description)\n    location = urllib.parse.quote(location)\n\n    def getGoogleLink():\n        link = \"https://calendar.google.com/calendar/render?action=TEMPLATE\"\n        if title:\n            link += f\"&text={title}\"\n        if start_time:\n            link += f\"&dates={start_time}\"\n        if end_time:\n            link += f\"/{end_time}\"\n        if description:\n            link += f\"&details={description}\"\n        if url:\n            link += f\"%20with%20URL:%20{url}\"\n        if location:\n            link += f\"&location={location}\"\n        return link\n\n    def getOutlookLink():\n\n        def datetime_to_ISO8601(datetime_str):\n            # Parse the input string using the specified format\n            datetime_obj = datetime.datetime.strptime(datetime_str, '%Y%m%dT%H%M%S')\n            # ISO8601\n            formatted_str = datetime_obj.strftime('%Y-%m-%dT%H%%3A%M%%3A%S')\n            return formatted_str\n\n        link = \"https://outlook.office.com/owa/?path=/calendar/action/compose&rru=addevent\"\n        if title:\n            link += f\"&subject={title}\"\n        if start_time:\n            link += f\"&startdt={datetime_to_ISO8601(start_time)}%2B00%3A00\"\n        if end_time:\n            link += f\"&enddt={datetime_to_ISO8601(end_time)}%2B00%3A00\"\n        if description:\n            link += f\"&body={description}\"\n        if url:\n            link += f\"%20with%20URL:%20{url}\"\n        if location:\n            link += f\"&location={location}\"\n        return link\n\n    SharedUtil.openURL(getOutlookLink() if calendar == \"outlook\" else getGoogleLink())\n\n    return \"Done!\"\n\nfunctionSignature = {\n    \"name\": \"add_calendar_event\",\n    \"description\": \"add calendar event\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"calendar\": {\n                \"type\": \"string\",\n                \"description\": \"The calendar application. Return 'google' if not given.\",\n                \"enum\": ['google', 'outlook'],\n            },\n            \"title\": {\n                \"type\": \"string\",\n                \"description\": \"The title of the event.\",\n            },\n            \"description\": {\n                \"type\": \"string\",\n                \"description\": \"The description of the event.\",\n            },\n            \"url\": {\n                \"type\": \"string\",\n                \"description\": \"Event url\",\n            },\n            \"start_time\": {\n                \"type\": \"string\",\n                \"description\": \"The start date and time of the event in the format `YYYYMMDDTHHmmss`. For example, `20220101T100000` represents January 1, 2022, at 10:00 AM.\",\n            },\n            \"end_time\": {\n                \"type\": \"string\",\n                \"description\": \"The end date and time of the event in the format `YYYYMMDDTHHmmss`. For example, `20220101T100000` represents January 1, 2022, at 10:00 AM. If not given, return 1 hour later than the start_time\",\n            },\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The location or venue of the event.\",\n            },\n        },\n        \"required\": [\"calendar\", \"title\", \"description\", \"start_time\", \"end_time\"],\n    },\n}\n\nconfig.addFunctionCall(name=\"add_calendar_event\", signature=functionSignature, method=add_calendar_event)\n```\n\n# A Step-by-step Guide\n\nWe wrote a step-by-step guide at:\n\nhttps://github.com/eliranwong/letmedoit/wiki/How-to-Write-a-Custom-Plugin\n\n# Passing Arguments from ChatGPT to the called functions\n\nRequired and optional arguments are first specified in \"functionSignature\".\n\nThey are passed to the called function as a dictionary.\n\nIn the example above, in \"[add calendar event](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/add%20calendar%20event.py)\", required arguments are \"calendar\", \"title\", \"description\" and \"start_time\" and optional arguments are \"url\", \"end_time\" and \"location\".  They are first specified in \"functionSignature\", then passed to the function \"add_calendar_event\" as a dictionary \"function_args\".  The arguments are then handled in the called function:\n\n```\ndef add_calendar_event(function_args):\n    calendar = function_args.get(\"calendar\") # required\n    title = function_args.get(\"title\") # required\n    description = function_args.get(\"description\") # required\n    url = function_args.get(\"url\", \"\") # optional\n    start_time = function_args.get(\"start_time\") # required\n    end_time = function_args.get(\"end_time\", \"\") # optional\n    location = function_args.get(\"location\", \"\") # optional\n    ...\n```\n\n# Returning Function Call Response to ChatGPT\n\nThe called function could end in several ways:\n\n1. Return information to extend chat conversation:\n\nFor example, in our plugin [search google](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/integrate%20google%20searches.py), the searched information is passed back to ChatGPT.\n\n```\ndef search_google(function_args):\n    # retrieve argument values from a dictionary\n    #print(function_args)\n    keywords = function_args.get(\"keywords\") # required\n    config.print(\"Loading internet searches ...\")\n    info = {}\n    for index, item in enumerate(googlesearch.search(keywords, advanced=True, num_results=config.maximumInternetSearchResults)):\n        info[f\"information {index}\"] = {\n            \"title\": item.title,\n            \"url\": item.url,\n            \"description\": item.description,\n        }\n    config.print(\"Loaded!\\n\")\n    return json.dumps(info)\n```\n\n2. Return a notification about the completion of executing the function\n\nFor example, in plugin [pronunce words](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/pronounce%20words.py), the function \"pronunce_words\" simply return \"Finished! Speech engine closed!\".\n\n```\ndef pronunce_words(function_args):\n    words = function_args.get(\"words\") # required\n    language = function_args.get(\"language\") # required\n    config.print(\"Loading speech feature ...\")\n    TTSUtil.play(words, language)\n    return \"Finished! Speech engine closed!\"\n```\n\n3. Ignore the call if the function is called by mistake\n\nReturn \"[INVALID]\" is a function is called by mistake. The original message is then passed to ChatGPT without a function call.\n\nFor example, in plugin \"[download YouTube media](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/download%20youtube%20or%20web%20content.py)\", the function \"download_youtube_media\" return \"[INVALID]\" if the given url is not a valid YouTube link.\n\n```\n        if is_youtube_url(url):\n            ...\n            return \"Finished! Youtube downloader closed!\"\n        else:\n            config.print(\"invalid link given\")\n            return \"[INVALID]\"\n```\n\n4. Return an empty string\n\nReturn an empty string \"\" if you just want to function to be executed without a follow-up text response to be generated.\n\nIn our plugin \"[search news](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/search%20latest%20news.py)\", the function \"search_news\" returns an empty string \"\" after it is executed.  No follow-up response is generated after the execution.\n\n# Use of config.tempContent\n\nUse config.tempContent to add context to the conversation messages even an empty string is returned by a function.\n\nWhen a function returns an empty string, it means that no additional information is added to the conversation messages with ChatGPT. This allows LetMeDoIt AI to run a function without extending the conversation. However, in certain situations, plugin developers may still want to include some information in the message chain as context, in case users continue the conversation and refer to the result generated by the function. In such cases, the `config.tempContent` can be used to add content to the conversation messages.\n\nTake our plugin \"[analyze images](https://github.com/eliranwong/letmedoit/blob/main/package/letmedoit/plugins/analyze%20images.py)\" as an example. The \"examine_images\" function returns an empty string after it is executed, which means the conversation with ChatGPT will not be extended. However, we \nstill want to add the image analysis result to the message chain so that users can refer to it in later conversations. In this case, we store the analysis result in `config.tempContent`, which is then picked up by the main program and added to the message chain for further reference.\n\nFor example, after instructing LetMeDoIt AI to describe an image, the user can refer to the description later to request new changes, e.g.\n\n> Describe the image in details\n\n> Change the background color to green\n\n```\ndef examine_images(function_args):\n    query = function_args.get(\"query\") # required\n    files = function_args.get(\"files\") # required\n...\n...\n...\n    if content:\n        content.insert(0, {\"type\": \"text\", \"text\": query,})\n        #print(content)\n        try:\n            response = OpenAI().chat.completions.create(\n                model=\"gpt-4-vision-preview\",\n                messages=[\n                    {\n                    \"role\": \"user\",\n                    \"content\": content,\n                    }\n                ],\n                max_tokens=4096,\n            )\n            answer = response.choices[0].message.content\n            config.print(answer)\n            config.tempContent = answer\n            return \"\"\n```\n\n# More about LetMeDoIt AI Plugins\n\nhttps://github.com/eliranwong/letmedoit/wiki/Plugins-%E2%80%90-Overview"
  },
  "doc-0eb61cb4713b99e844cf89f16fd9e657": {
    "content": "# For General Information\n\nhttps://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server\n\n# Ubuntu\n\nOfficial guide uses \"systemctl edit ollama.service\", however it does not work for some users.\n\nInstead, I use:\n\n> sudo nano /etc/systemd/system/ollama.service\n\nEdit the content, e.g.\n\n```\nRead [Unit]\nDescription=Ollama Service\nAfter=network-online.target\n\n[Service]\nExecStart=/usr/local/bin/ollama serve\nUser=ollama\nGroup=ollama\nRestart=always\nRestartSec=3\nEnvironment=\"OLLAMA_NUM_PARALLEL=4\"\nEnvironment=\"OLLAMA_MAX_LOADED_MODELS=4\"\n\n[Install]\nWantedBy=default.target\n```\n\nReload:\n\n> sudo systemctl daemon-reload\n\n> sudo systemctl restart ollama"
  }
}